//
//  This file is part of a concatenation of the CwlUtils framework with internal
//  interfaces for direct inclusion in projects instead of library inclusion).
//  For details, visit: https://github.com/mattgallagher/CwlUtils
//
//  Copyright Â© 2015-2019 Matt Gallagher ( https://www.cocoawithlove.com ). All rights reserved.
//
//  Permission to use, copy, modify, and/or distribute this software for any
//  purpose with or without fee is hereby granted, provided that the above
//  copyright notice and this permission notice appear in all copies.
//
//  THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
//  WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
//  MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY
//  SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
//  WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
//  ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR
//  IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
//
//  This file was generated by the CwlConcat tool on 2019-04-19 12:09:44 +0000 from the following files:
//   CwlAddressInfo.swift
//   CwlCaseNameCodable.swift
//   CwlCollection.swift
//   CwlCustomExecutionContext.swift
//   CwlDebugContext.swift
//   CwlDeferredWork.swift
//   CwlDeque.swift
//   CwlDispatch.swift
//   CwlExec.swift
//   CwlExecutionType.swift
//   CwlFew.swift
//   CwlKeyValueObserver.swift
//   CwlLifetime.swift
//   CwlMutex.swift
//   CwlOnDelete.swift
//   CwlRandom.swift
//   CwlResult.swift
//   CwlScalarScanner.swift
//   CwlSerializingContext.swift
//   CwlSysctl.swift
//   CwlWrappers.swift

import Foundation

/// A wrapper around dl_info, used for symbolicating instruction addresses.
struct AddressInfo {
	private let info: dl_info
	
	/// Address for which this struct was constructed
	let address: UInt
	
	/// Construct for an address
	init(address: UInt) {
		self.address = address

		var i = dl_info()
		dladdr(UnsafeRawPointer(bitPattern: address), &i)
		self.info = i
	}
	
	/// -returns: the "image" (shared object pathname) for the instruction
	var image: String {
		if let dli_fname = info.dli_fname, let fname = String(validatingUTF8: dli_fname), let _ = fname.range(of: "/", options: .backwards, range: nil, locale: nil) {
			return (fname as NSString).lastPathComponent
		} else {
			return "???"
		}
	}
	
	/// - returns: the symbol nearest the address
	var symbol: String {
		if let dli_sname = info.dli_sname, let sname = String(validatingUTF8: dli_sname) {
			return sname
		} else if let dli_fname = info.dli_fname, let _ = String(validatingUTF8: dli_fname) {
			return self.image
		} else {
			return String(format: "0x%1x", UInt(bitPattern: info.dli_saddr))
		}
	}
	
	/// - returns: the address' offset relative to the nearest symbol
	var offset: Int {
		if let dli_sname = info.dli_sname, let _ = String(validatingUTF8: dli_sname) {
			return Int(address - UInt(bitPattern: info.dli_saddr))
		} else if let dli_fname = info.dli_fname, let _ = String(validatingUTF8: dli_fname) {
			return Int(address - UInt(bitPattern: info.dli_fbase))
		} else {
			return Int(address - UInt(bitPattern: info.dli_saddr))
		}
	}
	
	/// - parameter index: the stack frame index
	/// - returns: a formatted string matching that used by NSThread.callStackSymbols
	func formattedDescription(index: Int) -> String {
		return self.image.utf8CString.withUnsafeBufferPointer { (imageBuffer: UnsafeBufferPointer<CChar>) -> String in
			#if arch(x86_64) || arch(arm64)
				return String(format: "%-4ld%-35s 0x%016llx %@ + %ld", index, UInt(bitPattern: imageBuffer.baseAddress), self.address, self.symbol, self.offset)
			#else
				return String(format: "%-4d%-35s 0x%08lx %@ + %d", index, UInt(bitPattern: imageBuffer.baseAddress), self.address, self.symbol, self.offset)
			#endif
		}
	}
}

/// When applied to the output of callStackReturnAddresses, produces identical output to the execinfo function "backtrace_symbols" or NSThread.callStackSymbols
/// - parameter addresses: an array of memory addresses, generally as produced by `callStackReturnAddresses`
/// - returns: an array of formatted, symbolicated stack frame descriptions.
func symbolsForCallStack(addresses: [UInt]) -> [String] {
	return Array(addresses.enumerated().map { tuple -> String in
		return AddressInfo(address: tuple.element).formattedDescription(index: tuple.offset)
	})
}

import Foundation

private struct EmptyKeyedDecodingContainer<K: CodingKey>: KeyedDecodingContainerProtocol {
	typealias Key = K
	
	var codingPath: [CodingKey] { return [] }
	var allKeys: [K] { return [] }
	
	func contains(_ key: K) -> Bool {
		return false
	}
	
	private func keyNotFoundError(_ key: K) -> Error {
		return DecodingError.keyNotFound(key, DecodingError.Context.init(codingPath: [], debugDescription: "EmptyKeyedDecodingContainer contains no values"))
	}
	
	func decodeNil(forKey key: K) throws -> Bool { throw keyNotFoundError(key) }
	func decode(_ type: Bool.Type, forKey key: K) throws -> Bool { throw keyNotFoundError(key) }
	func decode(_ type: String.Type, forKey key: K) throws -> String { throw keyNotFoundError(key) }
	func decode(_ type: Double.Type, forKey key: K) throws -> Double { throw keyNotFoundError(key) }
	func decode(_ type: Float.Type, forKey key: K) throws -> Float { throw keyNotFoundError(key) }
	func decode(_ type: Int.Type, forKey key: K) throws -> Int { throw keyNotFoundError(key) }
	func decode(_ type: Int8.Type, forKey key: K) throws -> Int8 { throw keyNotFoundError(key) }
	func decode(_ type: Int16.Type, forKey key: K) throws -> Int16 { throw keyNotFoundError(key) }
	func decode(_ type: Int32.Type, forKey key: K) throws -> Int32 { throw keyNotFoundError(key) }
	func decode(_ type: Int64.Type, forKey key: K) throws -> Int64 { throw keyNotFoundError(key) }
	func decode(_ type: UInt.Type, forKey key: K) throws -> UInt { throw keyNotFoundError(key) }
	func decode(_ type: UInt8.Type, forKey key: K) throws -> UInt8 { throw keyNotFoundError(key) }
	func decode(_ type: UInt16.Type, forKey key: K) throws -> UInt16 { throw keyNotFoundError(key) }
	func decode(_ type: UInt32.Type, forKey key: K) throws -> UInt32 { throw keyNotFoundError(key) }
	func decode(_ type: UInt64.Type, forKey key: K) throws -> UInt64 { throw keyNotFoundError(key) }
	func decode<T>(_ type: T.Type, forKey key: K) throws -> T where T : Decodable { throw keyNotFoundError(key) }
	func nestedContainer<NestedKey>(keyedBy type: NestedKey.Type, forKey key: K) throws -> KeyedDecodingContainer<NestedKey> where NestedKey : CodingKey { throw keyNotFoundError(key)	}
	func nestedUnkeyedContainer(forKey key: K) throws -> UnkeyedDecodingContainer { throw keyNotFoundError(key) }
	func superDecoder() throws -> Decoder { fatalError() }
	func superDecoder(forKey key: K) throws -> Decoder { throw keyNotFoundError(key) }
}

extension KeyedDecodingContainer {
	static func empty() -> KeyedDecodingContainer<K> {
		return KeyedDecodingContainer<K>(EmptyKeyedDecodingContainer())
	}
}

/// A protocol that enums with associated values can adopt to help in implementing Codable conformance.
/// The downside is that there are some runtime enforced requirements:
///  1. the `CaseName` associated type must be raw constructible from each of the case names in `CaseNameCodable`
///  2. the `decode(from:)` method must validly construct each `CaseNameCodable`
/// NOTE: the encoded value will be `nil` if the associated value has no contents or there is no associated value. In these cases, you shouldn't attempt to read the value.
protocol CaseNameCodable: Codable {
	associatedtype CaseName: CaseNameDecoder where CaseName.AssociatedEnum == Self
}

protocol CaseNameDecoder: Codable, CodingKey, RawRepresentable where RawValue == String {
	associatedtype AssociatedEnum
	func decode(from container: KeyedDecodingContainer<Self>) throws -> AssociatedEnum
}

extension CaseNameCodable {
	private func caseName(from mirror: Mirror) -> CaseName {
		let label = mirror.children.first?.label ?? String(describing: self)
		guard let key = CaseName(rawValue: label) else {
			fatalError("Unable to find a CaseName for \(self) matching \(label)")
		}
		return key
	}
	
	var caseName: CaseName {
		return caseName(from: Mirror(reflecting: self))
	}
	
	func encode(to encoder: Encoder) throws {
		let mirror = Mirror(reflecting: self)
		let key = caseName(from: mirror)
		var container = encoder.container(keyedBy: CaseName.self)
		if let value = mirror.children.first?.value as? Encodable {
			try container.encode(EncodableWrapper(value: value), forKey: key)
		} else {
			try container.encodeNil(forKey: key)
		}
	}
	
	init(from decoder: Decoder) throws {
		let container = try decoder.container(keyedBy: CaseName.self)
		guard let key = container.allKeys.first else {
			throw DecodingError.dataCorrupted(DecodingError.Context.init(codingPath: decoder.codingPath, debugDescription: "Missing enum key"))
		}
		self = try key.decode(from: container)
	}
}

private struct EncodableWrapper: Encodable {
	let value: Encodable
	
	func encode(to encoder: Encoder) throws {
		try value.encode(to: encoder)
	}
}

import Foundation

extension Optional {
	/// Reurns true if the current optional is nil. Useful for testing for nil at a specific point during chained unwrapping of nested optionals.
	var isNil: Bool {
		return self == nil
	}
}

extension Collection {
	/// Returns the element at the specified index iff it is within bounds, otherwise nil.
	func at(_ i: Index) -> Iterator.Element? {
		return (i >= startIndex && i < endIndex) ? self[i] : nil
	}
}

extension Collection {
	/// Constrains the range to the indices of self and returns a SubSequence.
	func at(_ range: Range<Index>) -> SubSequence {
		let start = (range.lowerBound >= startIndex) ? (range.lowerBound < endIndex ? range.lowerBound : endIndex) : startIndex
		let end = (range.upperBound < endIndex) ? (range.upperBound > startIndex ? range.upperBound : startIndex) : endIndex
		return self[start..<end]
	}
}

extension Collection where Index: Strideable, Index.Stride: SignedInteger {
	/// Constrains the range to the indices of self and returns a SubSequence.
	func at(_ range: CountableRange<Index>) -> SubSequence {
		let start = (range.lowerBound >= startIndex) ? (range.lowerBound < endIndex ? range.lowerBound : endIndex) : startIndex
		let end = (range.upperBound < endIndex) ? (range.upperBound > startIndex ? range.upperBound : startIndex) : endIndex
		return self[start..<end]
	}
}

extension RangeReplaceableCollection {
	static func +=(s: inout Self, e: Iterator.Element?) {
		guard let e = e else { return }
		s.append(e)
	}
	
	func appending(_ newElement: Iterator.Element) -> Self {
		var result = self
		result.append(newElement)
		return result
	}
}

import Foundation

/// An abstraction of common execution context concepts
protocol CustomExecutionContext {
	/// A description about how functions will be invoked on an execution context.
	var type: ExecutionType { get }
	
	/// Run `execute` normally on the execution context
	func invoke(_ execute: @escaping () -> Void)
	
	/// Run `execute` asynchronously on the execution context
	/// NOTE: a default implementation of this is provided that, if `type.isImmediate` is false, directly calls `invoke`, otherwise it runs an asynchronous block on the global dispatch queue and calls `invoke` from there.
	func invokeAsync(_ execute: @escaping () -> Void)
	
	/// Run `execute` on the execution context but don't return from this function until the provided function is complete.
	/// NOTE: a default implementation of this is provided that, if `type.isImmediate` is true, simply calls `invoke`, otherwise it calls `invoke` and blocks waiting on a semaphore in the calling context until `invoke` completes. Creating a semphore for every call is inefficient so you should implement this a different way, if possible.
	func invokeSync<Return>(_ execute: () throws -> Return) rethrows -> Return
	
	/// A context that can be used to safely escape the current context.
	/// NOTE: a default implementation of this function is provided that calls `DispatchQueue.global().async`. 
	/// - Parameter qos: The desired DispatchQoS.QoSClass for the new context. If `nil`, then inherit from `self` where possible
	func relativeAsync(qos: DispatchQoS.QoSClass?) -> Exec
	
	/// Run `execute` on the execution context after `interval` (plus `leeway`) unless the returned `Lifetime` is cancelled or released before running occurs.
	/// NOTE: a default implementation of this function is provided that runs the timer on the global dispatch queue and calls `invoke` when it fires. This implementation is likely sufficient for most cases but may not be appropriate if your context has strict timing or serialization requirements.
	func singleTimer(interval: DispatchTimeInterval, leeway: DispatchTimeInterval, handler: @escaping () -> Void) -> Lifetime
	
	/// Run `execute` on the execution context after `interval` (plus `leeway`), passing the `parameter` value as an argument, unless the returned `Lifetime` is cancelled or released before running occurs.
	/// NOTE: a default implementation of this function is provided that runs the timer on the global dispatch queue and calls `invoke` when it fires. This implementation is likely sufficient for most cases but may not be appropriate if your context has strict timing or serialization requirements.
	func singleTimer<T>(parameter: T, interval: DispatchTimeInterval, leeway: DispatchTimeInterval, handler: @escaping (T) -> Void) -> Lifetime
	
	/// Run `execute` on the execution context after `interval` (plus `leeway`), and again every `interval` (within a `leeway` margin of error) unless the returned `Lifetime` is cancelled or released before running occurs.
	/// NOTE: a default implementation of this function is provided that runs the timer on the global dispatch queue and calls `invoke` when it fires. This implementation is likely sufficient for most cases but may not be appropriate if your context has strict timing or serialization requirements.
	func periodicTimer(interval: DispatchTimeInterval, leeway: DispatchTimeInterval, handler: @escaping () -> Void) -> Lifetime
	
	/// Run `execute` on the execution context after `interval` (plus `leeway`), passing the `parameter` value as an argument, and again every `interval` (within a `leeway` margin of error) unless the returned `Lifetime` is cancelled or released before running occurs.
	/// NOTE: a default implementation of this function is provided that runs the timer on the global dispatch queue and calls `invoke` when it fires. This implementation is likely sufficient for most cases but may not be appropriate if your context has strict timing or serialization requirements.
	func periodicTimer<T>(parameter: T, interval: DispatchTimeInterval, leeway: DispatchTimeInterval, handler: @escaping (T) -> Void) -> Lifetime
	
	/// Gets a timestamp representing the host uptime the in the current context
	/// NOTE: a default implementation of this function is provided that calls `DispatchTime.now()`. With the exception of debug, test and other host-isolated contexts, this is usually sufficient. 
	func timestamp() -> DispatchTime
}

/// Many of the ExecutionContext functions returns a `Lifetime` and in most cases, that lifetime is just a dispatch timer. Annoyingly, a `DispatchSourceTimer` is an existential, so we can't extend it to conform to `Lifetime` (a limitation of Swift 4).
/// In these cases, you can force cast to DispatchSource and use this extension.
extension DispatchSource: Lifetime {
}

// Since it's not possible to have default parameters in protocols (yet) the "leeway" free functions are all default-implemented to call the "leeway" functions with a 0 second leeway.
extension CustomExecutionContext {
	func singleTimer(interval: DispatchTimeInterval, handler: @escaping () -> Void) -> Lifetime {
		return singleTimer(interval: interval, leeway: .seconds(0), handler: handler)
	}
	func singleTimer<T>(parameter: T, interval: DispatchTimeInterval, handler: @escaping (T) -> Void) -> Lifetime {
		return singleTimer(parameter: parameter, interval: interval, leeway: .seconds(0), handler: handler)
	}
	func periodicTimer(interval: DispatchTimeInterval, handler: @escaping () -> Void) -> Lifetime {
		return periodicTimer(interval: interval, leeway: .seconds(0), handler: handler)
	}
	func periodicTimer<T>(parameter: T, interval: DispatchTimeInterval, handler: @escaping (T) -> Void) -> Lifetime {
		return periodicTimer(parameter: parameter, interval: interval, leeway: .seconds(0), handler: handler)
	}
}

extension CustomExecutionContext {
	var isImmediateInCurrentContext: Bool { return type.isImmediateInCurrentContext }
	var isAsyncInCurrentContext: Bool { return type.isAsyncInCurrentContext }
	var isImmediateAlways: Bool { return type.isImmediateAlways }
	var isPotentiallyAsync: Bool { return type.isPotentiallyAsync }
	var isReentrant: Bool { return type.isReentrant }
	var isNonReentrant: Bool { return type.isNonReentrant }
	var isConcurrent: Bool { return type.isConcurrent }
	var isSerial: Bool { return type.isSerial }


	func timestamp() -> DispatchTime {
		return DispatchTime.now()
	}
	
	func invokeAsync(_ execute: @escaping () -> Void) {
		if type.isImmediateInCurrentContext == false {
			invoke(execute)
		} else {
			DispatchQueue.global().async { self.invoke(execute) }
		}
	}
	
	func invokeSync<Return>(_ execute: () -> Return) -> Return {
		return withoutActuallyEscaping(execute) { ex in
			var r: Return? = nil
			if type.isImmediateInCurrentContext == true {
				invoke {
					r = ex()
				}
			} else {
				let s = DispatchSemaphore(value: 0)
				self.invoke {
					r = ex()
					s.signal()
				}
				s.wait()
			}
			return r!
		}
	}
	
	func relativeAsync(qos: DispatchQoS.QoSClass?) -> Exec {
		return Exec.global(qos: qos ?? .default)
	}
	
	func singleTimer(interval: DispatchTimeInterval, leeway: DispatchTimeInterval, handler: @escaping () -> Void) -> Lifetime {
		return DispatchSource.singleTimer(interval: interval, leeway: leeway, queue: DispatchQueue.global(), handler: { self.invoke(handler) }) as! DispatchSource
	}
	
	func singleTimer<T>(parameter: T, interval: DispatchTimeInterval, leeway: DispatchTimeInterval, handler: @escaping (T) -> Void) -> Lifetime {
		return DispatchSource.singleTimer(parameter: parameter, interval: interval, leeway: leeway, queue: DispatchQueue.global(), handler: { p in self.invoke{ handler(p) } }) as! DispatchSource
	}
	
	func periodicTimer(interval: DispatchTimeInterval, leeway: DispatchTimeInterval, handler: @escaping () -> Void) -> Lifetime {
		return DispatchSource.repeatingTimer(interval: interval, leeway: leeway, queue: DispatchQueue.global(), handler: { self.invoke(handler) }) as! DispatchSource
	}
	
	func periodicTimer<T>(parameter: T, interval: DispatchTimeInterval, leeway: DispatchTimeInterval, handler: @escaping (T) -> Void) -> Lifetime {
		return DispatchSource.repeatingTimer(parameter: parameter, interval: interval, leeway: leeway, queue: DispatchQueue.global(), handler: { p in self.invoke{ handler(p) } }) as! DispatchSource
	}
}

@available(*, deprecated, message: "Use Exec for variables or CustomExecutionContext for conformances used in the `custom` case of Exec")
typealias ExecutionContext = CustomExecutionContext

import Foundation

/// A set of identifiers for the different queues in the DebugContextCoordinator
///
/// - unspecified: used when a initial DebugContextThread is not specified on startup (not used otherwise)
/// - main: used by `main` and `mainAsync` contexts
/// - `global`: used for a concurrent queues and for timers on direct
/// - custom: any custom queue
enum DebugContextThread: Hashable {
	case unspecified
	case main
	case global
	case custom(String)
	
	/// Convenience test to determine if an `Exec` instance wraps a `DebugContext` identifying `self` as its `thread`.
	func matches(_ exec: Exec) -> Bool {
		if case .custom(let debugContext as DebugContext) = exec, debugContext.thread == self {
			return true
		} else {
			return false
		}
	}
}

/// Basic equality tests for `DebugContextThread`
///
/// - Parameters:
///   - left: a `DebugContextThread`
///   - right: another `DebugContextThread`
/// - Returns: true if they are equal value
func ==(left: DebugContextThread, right: DebugContextThread) -> Bool {
	switch (left, right) {
	case (.custom(let l), .custom(let r)) where l == r: return true
	case (.unspecified, .unspecified): return true
	case (.main, .main): return true
	case (.global, .global): return true
	default: return false
	}
}

/// Simulates running a series of blocks across threads over time by instead queuing the blocks and running them serially in time priority order, incrementing the `currentTime` to reflect the time priority of the last run block.
/// The result is a deterministic simulation of time scheduled blocks, which is otherwise subject to thread scheduling non-determinism.
class DebugContextCoordinator {
	// We use DispatchTime for time calculations but time 0 is treated as a special value ("now") so we start at time = 1, internally, and subtract 1 when returning through the `currentTime` accessor.
	var internalTime: UInt64 = 1
	var queues: Dictionary<DebugContextThread, DebugContextQueue> = [:]
	var stopRequested: Bool = false
	
	/// Returns the current simulated time in nanoseconds
	var currentTime: UInt64 { return internalTime - 1 }
	
	/// Returns the last runs simulated thread
	fileprivate (set) var currentThread: DebugContextThread
	
	/// Constructs an empty instance
	init() {
		currentThread = .unspecified
	}
	
	/// Constructs an empty instance
	init(initialThread: DebugContextThread) {
		self.currentThread = initialThread
	}
	
	/// Implementation mimicking Exec.direct but returning an Exec.custom(DebugContext)
	var direct: Exec {
		return .custom(DebugContext(type: .immediate, thread: .global, coordinator: self))
	}
	
	/// Implementation mimicking Exec.main but returning an Exec.custom(DebugContext)
	var main: Exec {
		return .custom(DebugContext(type: .thread { [weak self] in self?.currentThread == .main }, thread: .main, coordinator: self))
	}
	
	/// Implementation mimicking Exec.mainAsync but returning an Exec.custom(DebugContext)
	var mainAsync: Exec {
		return .custom(DebugContext(type: .threadAsync { [weak self] in self?.currentThread == .main }, thread: .main, coordinator: self))
	}
	
	/// Implementation mimicking Exec.default but returning an Exec.custom(DebugContext)
	var global: Exec {
		return .custom(DebugContext(type: .concurrentAsync, thread: .global, coordinator: self))
	}
	
	/// Implementation mimicking Exec.syncQueue but returning an Exec.custom(DebugContext)
	func syncQueue() -> Exec {
		let uuidString = CFUUIDCreateString(nil, CFUUIDCreate(nil)) as String? ?? ""
		return .custom(DebugContext(type: .mutex, thread: .custom(uuidString), coordinator: self))
	}
	
	/// Implementation mimicking Exec.asyncQueue but returning an Exec.custom(DebugContext)
	func asyncQueue() -> Exec {
		let uuidString = CFUUIDCreateString(nil, CFUUIDCreate(nil)) as String? ?? ""
		return .custom(DebugContext(type: .serialAsync, thread: .custom(uuidString), coordinator: self))
	}
	
	/// Performs all scheduled actions in a serial loop.
	///
	/// - parameter stoppingAfter: If nil, loop will continue until `stop` invoked or until no actions remain. If non-nil, loop will abort after an action matching Lifetime is completed.
	func runScheduledTasks(stoppingAfter: (AnyObject & Lifetime)? = nil) {
		stopRequested = false
		currentThread = .unspecified
		while !stopRequested, let nextTimer = runNextTask() {
			if stoppingAfter != nil, stoppingAfter === nextTimer {
				break
			}
		}
		if stopRequested {
			// Since releasing `queues` will likely cause the release of closures and items held by the queue, which might lead to nested calls to remove items from `queues` violating ownership rules...
			// We copy queues to a non-shared stack location, clear `queues` and *then* release the contents.
			withExtendedLifetime(queues) { queues = [:] }
		}
	}
	
	/// Performs all scheduled actions in a serial loop.
	///
	/// - parameter stoppingAfter: If nil, loop will continue until `stop` invoked or until no actions remain. If non-nil, loop will abort after an action matching Lifetime is completed.
	func runScheduledTasks(untilTime: UInt64) {
		stopRequested = false
		currentThread = .unspecified
		while !stopRequested, let (threadIndex, time) = nextTask(), time <= untilTime {
			_ = runTask(threadIndex: threadIndex, time: time)
		}
		if stopRequested {
			// Since releasing `queues` will likely cause the release of closures and items held by the queue, which might lead to nested calls to remove items from `queues` violating ownership rules...
			// We copy queues to a non-shared stack location, clear `queues` and *then* release the contents.
			withExtendedLifetime(queues) { queues = [:] }
		}
	}
	
	/// Causes `runScheduledTasks` to exit as soon as possible, if it is running.
	func stop() {
		stopRequested = true
	}
	
	/// Discards all scheduled actions and resets time to 1. Useful if the `DebugContextCoordinator` is to be reused.
	func reset() {
		internalTime = 1
		
		// Since releasing `queues` will likely cause the release of closures and items held by the queue, which might lead to nested calls to remove items from `queues` violating ownership rules...
		// We copy queues to a non-shared stack location, clear `queues` and *then* release the contents.
		withExtendedLifetime(queues) { queues = [:] }
	}
	
	func getOrCreateQueue(forName: DebugContextThread) -> DebugContextQueue {
		if let t = queues[forName] {
			return t
		}
		let t = DebugContextQueue()
		
		// Since releasing `queues` will likely cause the release of closures and items held by the queue, which might lead to nested calls to remove items from `queues` violating ownership rules...
		// We copy queues to a non-shared stack location, clear `queues` and *then* release the contents.
		withExtendedLifetime(queues[forName]) { queues[forName] = t }
		
		return t
	}
	
	// Fundamental method for scheduling a block on the coordinator for later invocation.
	func schedule(block: @escaping () -> Void, thread: DebugContextThread, timeInterval interval: Int64, repeats: Bool) -> DebugContextTimer {
		let i = interval > 0 ? UInt64(interval) : 0 as UInt64
		let debugContextTimer = DebugContextTimer(thread: thread, rescheduleInterval: repeats ? i : nil, coordinator: self)
		getOrCreateQueue(forName: thread).schedule(pending: PendingBlock(time: internalTime + i, timer: debugContextTimer, block: block))
		return debugContextTimer
	}
	
	// Remove a block from the scheduler
	func cancelTimer(_ toCancel: DebugContextTimer) {
		if let t = queues[toCancel.thread]  {
			t.cancelTimer(toCancel)
		}
	}
	
	func nextTask() -> (DebugContextThread, UInt64)? {
		var lowestTime = UInt64.max
		var selectedIndex = DebugContextThread.unspecified
		
		// We want a deterministic ordering, so we'll iterate over the queues by key sorted by hashValue
		for index in queues.keys.sorted(by: { (left, right) -> Bool in left.hashValue < right.hashValue }) {
			if let t = queues[index], t.nextTime < lowestTime {
				selectedIndex = index
				lowestTime = t.nextTime
			}
		}
		if lowestTime == UInt64.max {
			return nil
		}
		
		return (selectedIndex, lowestTime)
	}
	
	func runTask(threadIndex: DebugContextThread, time: UInt64) -> DebugContextTimer? {
		(currentThread, internalTime) = (threadIndex, time)
		return queues[threadIndex]?.popAndInvokeNext()
	}
	
	// Run the next event. If nil is returned, no further events remain. If
	func runNextTask() -> DebugContextTimer? {
		if let (threadIndex, time) = nextTask() {
			return runTask(threadIndex: threadIndex, time: time)
		}
		return nil
	}
}

// This structure is used to represent scheduled actions in the DebugContextCoordinator.
struct PendingBlock {
	let time: UInt64
	weak var timer: DebugContextTimer?
	let block: () -> Void
	
	init(time: UInt64, timer: DebugContextTimer?, block: @escaping () -> Void) {
		self.time = time
		self.timer = timer
		self.block = block
	}
	
	var nextInterval: PendingBlock? {
		if let t = timer, let i = t.rescheduleInterval, t.coordinator != nil {
			return PendingBlock(time: time + i, timer: t, block: block)
		}
		return nil
	}
}

// A `DebugContextQueue` is just an array of `PendingBlock`, sorted by scheduled time. It represents the blocks queued for execution on a thread in the `DebugContextCoordinator`.
class DebugContextQueue {
	var pendingBlocks: Array<PendingBlock> = []
	
	init() {
	}
	
	// Insert a block in scheduled order
	func schedule(pending: PendingBlock) {
		var insertionIndex = 0
		while pendingBlocks.count > insertionIndex && pendingBlocks[insertionIndex].time <= pending.time {
			insertionIndex += 1
		}
		
		pendingBlocks.insert(pending, at: insertionIndex)
	}
	
	// Remove a block
	func cancelTimer(_ toCancel: DebugContextTimer) {
		if let index = pendingBlocks.firstIndex(where: { tuple -> Bool in tuple.timer === toCancel }) {
			pendingBlocks.remove(at: index)
		}
	}
	
	// Return the earliest scheduled time in the queue
	var nextTime: UInt64 {
		return pendingBlocks.first?.time ?? UInt64.max
	}
	
	// Runs the next block in the queue
	func popAndInvokeNext() -> DebugContextTimer? {
		if let next = pendingBlocks.first {
			pendingBlocks.remove(at: 0)
			next.block()
			if let nextInterval = next.nextInterval {
				schedule(pending: nextInterval)
			}
			
			// We ran a block, don't return nil (next.timer may return nil if it has self-cancelled)
			return next.timer ?? DebugContextTimer()
		}
		
		return nil
	}
}

/// An implementation of `ExecutionContext` that schedules its non-immediate actions on a `DebugContextCoordinator`. This type is constructed using the `Exec` mimicking properties and functions on `DebugContextCoordinator`.
struct DebugContext: CustomExecutionContext {
	let type: ExecutionType
	let thread: DebugContextThread
	weak var coordinator: DebugContextCoordinator?
	
	init(type: ExecutionType, thread: DebugContextThread, coordinator: DebugContextCoordinator) {
		self.type = type
		self.thread = thread
		self.coordinator = coordinator
	}
	
	/// Run `execute` normally on the execution context
	func invoke(_ execute: @escaping () -> Void) {
		guard let c = coordinator else { return }
		if type.isImmediateInCurrentContext {
			let previousThread = c.currentThread
			if !type.isConcurrent {
				c.currentThread = thread
			}
			execute()
			if !type.isConcurrent {
				c.currentThread = previousThread
			}
		} else {
			invokeAsync(execute)
		}
	}
	
	/// Run `execute` asynchronously on the execution context
	func invokeAsync(_ execute: @escaping () -> Void) {
		_ = coordinator?.schedule(block: execute, thread: thread, timeInterval: 1, repeats: false)
	}
	
	@available(*, deprecated, message: "Use invokeSync instead")
	func invokeAndWait(_ execute: @escaping () -> Void) {
		_ = invokeSync(execute)
	}
	
	/// Run `execute` on the execution context but don't return from this function until the provided function is complete.
	///
	/// If the debug coordinator is nil or has completed before this block is run, the block will be directly invoked instead of running in the debug context.
	/// In general this shouldn't matter since the debug context is generally just a synchronous invocation.
	///
	/// - Parameter execute: the block to run
	/// - Returns: the return value from running the block
	func invokeSync<Return>(_ execute: () throws -> Return) rethrows -> Return {
		guard let c = coordinator else {
			return try execute()
		}
		if type.isImmediateInCurrentContext {
			let previousThread = c.currentThread
			if !type.isConcurrent {
				c.currentThread = thread
			}
			let r = try execute()
			if !type.isConcurrent {
				c.currentThread = previousThread
			}
			return r
		} else {
			let result = try withoutActuallyEscaping(execute) { ex throws -> Return? in
				var rr: Result<Return, Error>? = nil
				c.runScheduledTasks(stoppingAfter: c.schedule(block: {
					rr = Result { try ex() }
				}, thread: thread, timeInterval: 1, repeats: false))
				return try rr?.get()
			}
			guard let r = result else { return try execute() }
			return r
		}
	}
	
	func relativeAsync(qos: DispatchQoS.QoSClass?) -> Exec {
		guard let c = coordinator else {
			return Exec.direct
		}
		return c.global
	}
	
	/// Run `execute` on the execution context after `interval` (plus `leeway`) unless the returned `Lifetime` is cancelled or released before running occurs.
	func singleTimer(interval: DispatchTimeInterval, leeway: DispatchTimeInterval, handler: @escaping () -> Void) -> Lifetime {
		guard let c = coordinator else { return DebugContextTimer() }
		return c.schedule(block: handler, thread: thread, timeInterval: interval.nanoseconds, repeats: false)
	}
	
	/// Run `execute` on the execution context after `interval` (plus `leeway`), passing the `parameter` value as an argument, unless the returned `Lifetime` is cancelled or released before running occurs.
	func singleTimer<T>(parameter: T, interval: DispatchTimeInterval, leeway: DispatchTimeInterval, handler: @escaping (T) -> Void) -> Lifetime {
		guard let c = coordinator else { return DebugContextTimer() }
		return c.schedule(block: { handler(parameter) }, thread: thread, timeInterval: interval.nanoseconds, repeats: false)
	}
	
	/// Run `execute` on the execution context after `interval` (plus `leeway`), and again every `interval` (within a `leeway` margin of error) unless the returned `Lifetime` is cancelled or released before running occurs.
	func periodicTimer(interval: DispatchTimeInterval, leeway: DispatchTimeInterval, handler: @escaping () -> Void) -> Lifetime {
		guard let c = coordinator else { return DebugContextTimer() }
		return c.schedule(block: handler, thread: thread, timeInterval: interval.nanoseconds, repeats: true)
	}
	
	/// Run `execute` on the execution context after `interval` (plus `leeway`), passing the `parameter` value as an argument, and again every `interval` (within a `leeway` margin of error) unless the returned `Lifetime` is cancelled or released before running occurs.
	func periodicTimer<T>(parameter: T, interval: DispatchTimeInterval, leeway: DispatchTimeInterval, handler: @escaping (T) -> Void) -> Lifetime {
		guard let c = coordinator else { return DebugContextTimer() }
		return c.schedule(block: { handler(parameter) }, thread: thread, timeInterval: interval.nanoseconds, repeats: true)
	}
	
	/// Gets a timestamp representing the host uptime the in the current context
	func timestamp() -> DispatchTime {
		guard let c = coordinator else { return DispatchTime.now() }
		return DispatchTime(uptimeNanoseconds: c.currentTime)
	}
}

// All actions scheduled with a `DebugContextCoordinator` are referenced by a DebugContextTimer (even those actions that are simply asynchronous invocations without a delay).
class DebugContextTimer: Lifetime {
	let thread: DebugContextThread
	let rescheduleInterval: UInt64?
	weak var coordinator: DebugContextCoordinator?
	
	init() {
		thread = .unspecified
		coordinator = nil
		rescheduleInterval = nil
	}
	
	init(thread: DebugContextThread, rescheduleInterval: UInt64?, coordinator: DebugContextCoordinator) {
		self.thread = thread
		self.coordinator = coordinator
		self.rescheduleInterval = rescheduleInterval
	}
	
	/// Lifetime implementation
	func cancel() {
		coordinator?.cancelTimer(self)
		coordinator = nil
	}
	
	deinit {
		cancel()
	}
}

import Foundation

// This type is designed for guarding against mutex re-entrancy by following two simple rules:
//
//  1. No user "work" (functions or closures) should be invoked inside a private mutex
//  2. No user supplied data should be released inside a private mutex
//
// To facilitate these requirements, any user "work" or data ownership should be handled inside `DeferredWork` blocks. These blocks allow this user code to be queued in the desired order but since the `runWork` function should only be called outside the mutex, these blocks run safely outside the mutex.
//
// This pattern has two associated risks:
//  1. If the deferred work calls back into the mutex, it must be able to ensure that it is still relevant (hasn't been superceded by an action that may have occurred between the end of the mutex and the performing of the `DeferredWork`. This may involve a token (inside the mutex, only the most recent token is accepted) or the mutex queueing further requests until the most recent `DeferredWork` completes.
//  2. The `runWork` must be manually invoked. Automtic invocation (e.g in the `deinit` of a lifetime managed `class` instance) would add heap allocation overhead and would also be easy to accidentally release at the wrong point (inside the mutex) causing erratic problems. Instead, the `runWork` is guarded with a `DEBUG`-only `OnDelete` check that ensures that the `runWork` has been correctly invoked by the time the `DeferredWork` falls out of scope.
struct DeferredWork {
	typealias PossibleWork = Few<() -> Void>
	
	var work: PossibleWork

	#if DEBUG
		let invokeCheck: OnDelete = { () -> OnDelete in
			var sourceStack = Thread.callStackReturnAddresses
			return OnDelete {
				let symbols = symbolsForCallStack(addresses: sourceStack.map { $0.uintValue })
				preconditionFailure("Failed to perform work deferred at location:\n" + symbols.joined(separator: "\n"))
			}
		}()
	#endif

	init() {
		work = .none
	}
	
	init(initial: @escaping () -> Void) {
		work = .single(initial)
	}
	
	mutating func append(_ other: DeferredWork) {
		#if DEBUG
			precondition(invokeCheck.isValid && other.invokeCheck.isValid, "Work appended to an already cancelled/invoked DeferredWork")
				other.invokeCheck.invalidate()
		#endif
		
		switch other.work {
		case .none: break
		case .single(let otherWork): self.append(otherWork)
		case .array(let otherWork):
			switch work {
			case .none: work = .array(otherWork)
			case .single(let existing):
				var newWork: Array<() -> Void> = [existing]
				newWork.append(contentsOf: otherWork)
				work = .array(newWork)
			case .array(var existing):
				work = .none
				existing.append(contentsOf: otherWork)
				work = .array(existing)
			}
		}
	}
	
	mutating func append(_ additionalWork: @escaping () -> Void) {
		#if DEBUG
			precondition(invokeCheck.isValid, "Work appended to an already cancelled/invoked DeferredWork")
		#endif
		
		switch work {
		case .none: work = .single(additionalWork)
		case .single(let existing): work = .array([existing, additionalWork])
		case .array(var existing):
			work = .none
			existing.append(additionalWork)
			work = .array(existing)
		}
	}
	
	mutating func runWork() {
		#if DEBUG
			precondition(invokeCheck.isValid, "Work run multiple times")
			invokeCheck.invalidate()
		#endif
		
		switch work {
		case .none: break
		case .single(let w): w()
		case .array(let ws):
			for w in ws {
				w()
			}
		}
		work = .none
	}
}

import Foundation

/// This is a basic "circular-buffer" style Double-Ended Queue.
struct Deque<T>: RandomAccessCollection, MutableCollection, RangeReplaceableCollection, ExpressibleByArrayLiteral, CustomDebugStringConvertible {
	typealias Index = Int
	typealias Indices = CountableRange<Int>
	typealias Element = T
	
	private let overAllocateFactor = 2
	private let downsizeTriggerFactor = 16
	private let defaultMinimumCapacity = 5
	
	private var buffer: DequeBuffer<T>? = nil
	private var minCapacity: Int
	
	/// Implementation of RangeReplaceableCollection function
	init() {
		self.minCapacity = defaultMinimumCapacity
	}
	
	/// Allocate with a minimum capacity
	init(minCapacity: Int) {
		self.minCapacity = minCapacity
	}
	
	/// Implementation of ExpressibleByArrayLiteral function
	init(arrayLiteral: T...) {
		self.minCapacity = defaultMinimumCapacity
		replaceSubrange(0..<0, with: arrayLiteral)
	}
	
	/// Implementation of CustomDebugStringConvertible function
	var debugDescription: String {
		var result = "\(type(of: self))(["
		var iterator = makeIterator()
		if let next = iterator.next() {
			debugPrint(next, terminator: "", to: &result)
			while let n = iterator.next() {
				result += ", "
				debugPrint(n, terminator: "", to: &result)
			}
		}
		result += "])"
		return result
	}
	
	#if swift(>=4.1)
		subscript(bounds: Range<Index>) -> Slice<Deque<T>> {
			return Slice<Deque<T>>(base: self, bounds: bounds)
		}
	#else
		subscript(bounds: Range<Index>) -> RangeReplaceableRandomAccessSlice<Deque<T>> {
			return RangeReplaceableRandomAccessSlice<Deque<T>>(base: self, bounds: bounds)
		}
	#endif
	
	/// Implementation of RandomAccessCollection function
	subscript(_ at: Index) -> T {
		get {
			return buffer!.withUnsafeMutablePointers { headerPtr, bodyPtr -> T in
				precondition(at >= 0 && at < headerPtr.pointee.count)
				var offset = headerPtr.pointee.offset + at
				if offset >= headerPtr.pointee.capacity {
					offset -= headerPtr.pointee.capacity
				}
				return bodyPtr[offset]
			}
		}
		set {
			buffer!.withUnsafeMutablePointers { headerPtr, bodyPtr in
				precondition(at >= 0 && at < headerPtr.pointee.count)
				var offset = headerPtr.pointee.offset + at
				if offset >= headerPtr.pointee.capacity {
					offset -= headerPtr.pointee.capacity
				}
				bodyPtr[offset] = newValue
			}
		}
	}
	
	/// Implementation of Collection function
	var startIndex: Index {
		return 0
	}
	
	/// Implementation of Collection function
	var endIndex: Index {
		return buffer?.withUnsafeMutablePointerToHeader { headerPtr in headerPtr.pointee.count } ?? 0
	}
	
	/// Implementation of Collection function
	var isEmpty: Bool {
		return buffer?.withUnsafeMutablePointerToHeader { headerPtr in headerPtr.pointee.count == 0 } ?? true
	}
	
	/// Implementation of Collection function
	var count: Int {
		return endIndex
	}
	
	/// Optimized implementation of RangeReplaceableCollection function
	mutating func append(_ newElement: T) {
		let done = buffer?.withUnsafeMutablePointers { headerPtr, bodyPtr -> Bool in
			guard headerPtr.pointee.capacity >= headerPtr.pointee.count + 1 else { return false }
			var index = headerPtr.pointee.offset + headerPtr.pointee.count
			if index >= headerPtr.pointee.capacity {
				index -= headerPtr.pointee.capacity
			}
			bodyPtr.advanced(by: index).initialize(to: newElement)
			headerPtr.pointee.count += 1
			return true
		} ?? false
		
		if done {
			return
		}
		
		let index = endIndex
		return replaceSubrange(index..<index, with: CollectionOfOne(newElement))
	}
	
	/// Optimized implementation of RangeReplaceableCollection function
	mutating func insert(_ newElement: T, at: Int) {
		let done = buffer?.withUnsafeMutablePointers { headerPtr, bodyPtr -> Bool in
			guard at == 0, headerPtr.pointee.capacity >= headerPtr.pointee.count + 1 else { return false }
			var index = headerPtr.pointee.offset - 1
			if index < 0 {
				index += headerPtr.pointee.capacity
			}
			bodyPtr.advanced(by: index).initialize(to: newElement)
			headerPtr.pointee.count += 1
			headerPtr.pointee.offset = index
			return true
		} ?? false
		
		if done {
			return
		}
		
		return replaceSubrange(at..<at, with: CollectionOfOne(newElement))
	}
	
	/// Optimized implementation of RangeReplaceableCollection function
	mutating func remove(at: Int) {
		let done = buffer?.withUnsafeMutablePointers { headerPtr, bodyPtr -> Bool in
			if at == headerPtr.pointee.count - 1 {
				headerPtr.pointee.count -= 1
				return true
			} else if at == 0, headerPtr.pointee.count > 0 {
				headerPtr.pointee.offset += 1
				if headerPtr.pointee.offset >= headerPtr.pointee.capacity {
					headerPtr.pointee.offset -= headerPtr.pointee.capacity
				}
				headerPtr.pointee.count -= 1
				return true
			}
			return false
		} ?? false
		
		if done {
			return
		}
		
		return replaceSubrange(at...at, with: EmptyCollection())
	}
	
	/// Optimized implementation of RangeReplaceableCollection function
	mutating func removeFirst() -> T {
		return buffer!.withUnsafeMutablePointers { headerPtr, bodyPtr -> T in
			precondition(headerPtr.pointee.count > 0, "Index beyond bounds")
			let result = bodyPtr[headerPtr.pointee.offset]
			#if swift(>=4.1)
				bodyPtr.advanced(by: headerPtr.pointee.offset).deinitialize(count: 1)
			#else
				bodyPtr.advanced(by: headerPtr.pointee.offset).deinitialize()
			#endif
			headerPtr.pointee.offset += 1
			if headerPtr.pointee.offset >= headerPtr.pointee.capacity {
				headerPtr.pointee.offset -= headerPtr.pointee.capacity
			}
			headerPtr.pointee.count -= 1
			return result
		}
	}
	
	// Used when removing a range from the collection or deiniting self.
	private static func deinitialize(range: CountableRange<Int>, header: UnsafeMutablePointer<DequeHeader>, body: UnsafeMutablePointer<T>) {
		let splitRange = header.pointee.splitRangeIndices(inRange: range)
		body.advanced(by: splitRange.low.startIndex).deinitialize(count: splitRange.low.count)
		body.advanced(by: splitRange.high.startIndex).deinitialize(count: splitRange.high.count)
	}
	
	// Move from an initialized to an uninitialized location, deinitializing the source.
	//
	// NOTE: the terms "preMapped" and "postMapped" are used. "preMapped" refer to the indices exposed by this type (zero based, contiguous), and "postMapped" refers to internal offsets within the buffer (not necessarily zero based and may wrap around). This function will only handle a single, contiguous block of "postMapped" indices so the caller must ensure that this function is invoked separately for each contiguous block.
	private static func moveInitialize(preMappedSourceRange: CountableRange<Int>, postMappedDestinationRange: CountableRange<Int>, sourceHeader: UnsafeMutablePointer<DequeHeader>, sourceBody: UnsafeMutablePointer<T>, destinationBody: UnsafeMutablePointer<T>) {
		let sourceSplitRange = sourceHeader.pointee.splitRangeIndices(inRange: preMappedSourceRange)
		
		assert(sourceSplitRange.low.startIndex >= 0 && (sourceSplitRange.low.startIndex < sourceHeader.pointee.capacity || sourceSplitRange.low.startIndex == sourceSplitRange.low.endIndex))
		assert(sourceSplitRange.low.endIndex >= 0 && sourceSplitRange.low.endIndex <= sourceHeader.pointee.capacity)
		
		assert(sourceSplitRange.high.startIndex >= 0 && (sourceSplitRange.high.startIndex < sourceHeader.pointee.capacity || sourceSplitRange.high.startIndex == sourceSplitRange.high.endIndex))
		assert(sourceSplitRange.high.endIndex >= 0 && sourceSplitRange.high.endIndex <= sourceHeader.pointee.capacity)
		
		destinationBody.advanced(by: postMappedDestinationRange.startIndex).moveInitialize(from: sourceBody.advanced(by: sourceSplitRange.low.startIndex), count: sourceSplitRange.low.count)
		destinationBody.advanced(by: postMappedDestinationRange.startIndex + sourceSplitRange.low.count).moveInitialize(from: sourceBody.advanced(by: sourceSplitRange.high.startIndex), count: sourceSplitRange.high.count)
	}
	
	// Copy from an initialized to an uninitialized location, leaving the source initialized.
	//
	// NOTE: the terms "preMapped" and "postMapped" are used. "preMapped" refer to the indices exposed by this type (zero based, contiguous), and "postMapped" refers to internal offsets within the buffer (not necessarily zero based and may wrap around). This function will only handle a single, contiguous block of "postMapped" indices so the caller must ensure that this function is invoked separately for each contiguous block.
	private static func copyInitialize(preMappedSourceRange: CountableRange<Int>, postMappedDestinationRange: CountableRange<Int>, sourceHeader: UnsafeMutablePointer<DequeHeader>, sourceBody: UnsafeMutablePointer<T>, destinationBody: UnsafeMutablePointer<T>) {
		let sourceSplitRange = sourceHeader.pointee.splitRangeIndices(inRange: preMappedSourceRange)
		
		assert(sourceSplitRange.low.startIndex >= 0 && (sourceSplitRange.low.startIndex < sourceHeader.pointee.capacity || sourceSplitRange.low.startIndex == sourceSplitRange.low.endIndex))
		assert(sourceSplitRange.low.endIndex >= 0 && sourceSplitRange.low.endIndex <= sourceHeader.pointee.capacity)
		
		assert(sourceSplitRange.high.startIndex >= 0 && (sourceSplitRange.high.startIndex < sourceHeader.pointee.capacity || sourceSplitRange.high.startIndex == sourceSplitRange.high.endIndex))
		assert(sourceSplitRange.high.endIndex >= 0 && sourceSplitRange.high.endIndex <= sourceHeader.pointee.capacity)
		
		destinationBody.advanced(by: postMappedDestinationRange.startIndex).initialize(from: sourceBody.advanced(by: sourceSplitRange.low.startIndex), count: sourceSplitRange.low.count)
		destinationBody.advanced(by: postMappedDestinationRange.startIndex + sourceSplitRange.low.count).initialize(from: sourceBody.advanced(by: sourceSplitRange.high.startIndex), count: sourceSplitRange.high.count)
	}
	
	// Internal implementation of replaceSubrange<C>(_:with:) when no reallocation
	// of the underlying buffer is required
	private static func mutateWithoutReallocate<C>(info: DequeMutationInfo2, elements newElements: C, header: UnsafeMutablePointer<DequeHeader>, body: UnsafeMutablePointer<T>) where C: Collection, C.Iterator.Element == T {
		if info.removed > 0 {
			Deque.deinitialize(range: info.start..<(info.start + info.removed), header: header, body: body)
		}
		
		if info.removed != info.inserted {
			if info.start < header.pointee.count - (info.start + info.removed) {
				let oldOffset = header.pointee.offset
				header.pointee.offset -= info.inserted - info.removed
				if header.pointee.offset < 0 {
					header.pointee.offset += header.pointee.capacity
				} else if header.pointee.offset >= header.pointee.capacity {
					header.pointee.offset -= header.pointee.capacity
				}
				let delta = oldOffset - header.pointee.offset
				if info.start != 0 {
					let destinationSplitIndices = header.pointee.splitRangeIndices(inRange: 0..<info.start)
					let lowCount = destinationSplitIndices.low.count
					Deque.moveInitialize(preMappedSourceRange: delta..<(delta + lowCount), postMappedDestinationRange: destinationSplitIndices.low, sourceHeader: header, sourceBody: body, destinationBody: body)
					if lowCount != info.start {
						Deque.moveInitialize(preMappedSourceRange: (delta + lowCount)..<(info.start + delta), postMappedDestinationRange: destinationSplitIndices.high, sourceHeader: header, sourceBody: body, destinationBody: body)
					}
				}
			} else {
				if (info.start + info.removed) != header.pointee.count {
					let start = info.start + info.removed
					let end = header.pointee.count
					let destinationSplitIndices = header.pointee.splitRangeIndices(inRange: (info.start + info.inserted)..<(end - info.removed + info.inserted))
					let lowCount = destinationSplitIndices.low.count
					
					Deque.moveInitialize(preMappedSourceRange: start..<end, postMappedDestinationRange: destinationSplitIndices.low, sourceHeader: header, sourceBody: body, destinationBody: body)
					if lowCount != end - start {
						Deque.moveInitialize(preMappedSourceRange: (start + lowCount)..<end, postMappedDestinationRange: destinationSplitIndices.high, sourceHeader: header, sourceBody: body, destinationBody: body)
					}
				}
			}
			header.pointee.count = header.pointee.count - info.removed + info.inserted
		}
		
		if info.inserted == 1, let e = newElements.first {
			if info.start >= header.pointee.capacity - header.pointee.offset {
				body.advanced(by: info.start - header.pointee.capacity + header.pointee.offset).initialize(to: e)
			} else {
				body.advanced(by: header.pointee.offset + info.start).initialize(to: e)
			}
		} else if info.inserted > 0 {
			let inserted = header.pointee.splitRangeIndices(inRange: info.start..<(info.start + info.inserted))
			var iterator = newElements.makeIterator()
			for i in inserted.low {
				if let n = iterator.next() {
					body.advanced(by: i).initialize(to: n)
				}
			}
			for i in inserted.high {
				if let n = iterator.next() {
					body.advanced(by: i).initialize(to: n)
				}
			}
		}
	}
	
	// Internal implementation of replaceSubrange<C>(_:with:) when reallocation
	// of the underlying buffer is required. Can handle no previous buffer or
	// previous buffer too small or previous buffer too big or previous buffer
	// non-unique.
	private mutating func reallocateAndMutate<C>(info: DequeMutationInfo2, elements newElements: C, header: UnsafeMutablePointer<DequeHeader>?, body: UnsafeMutablePointer<T>?, deletePrevious: Bool) where C: Collection, C.Iterator.Element == T {
		if info.newCount == 0 {
			// Let the regular deallocation handle the deinitialize
			buffer = nil
		} else {
			let newCapacity: Int
			let oldCapacity = header?.pointee.capacity ?? 0
			if info.newCount > oldCapacity || info.newCount <= oldCapacity / downsizeTriggerFactor {
				newCapacity = Swift.max(minCapacity, info.newCount * overAllocateFactor)
			} else {
				newCapacity = oldCapacity
			}
			
			let newBuffer = DequeBuffer<T>.create(minimumCapacity: newCapacity) { (buffer: ManagedBuffer<DequeHeader, T>) in
				return DequeHeader(offset: 0, count: info.newCount, capacity: newCapacity)
			} as! DequeBuffer<T>
			if let headerPtr = header, let bodyPtr = body {
				if deletePrevious, info.removed > 0 {
					Deque.deinitialize(range: info.start..<(info.start + info.removed), header: headerPtr, body: bodyPtr)
				}
				
				newBuffer.withUnsafeMutablePointerToElements { newBody in
					if info.start != 0 {
						if deletePrevious {
							Deque.moveInitialize(preMappedSourceRange: 0..<info.start, postMappedDestinationRange: 0..<info.start, sourceHeader: headerPtr, sourceBody: bodyPtr, destinationBody: newBody)
						} else {
							Deque.copyInitialize(preMappedSourceRange: 0..<info.start, postMappedDestinationRange: 0..<info.start, sourceHeader: headerPtr, sourceBody: bodyPtr, destinationBody: newBody)
						}
					}
					
					let oldCount = header?.pointee.count ?? 0
					if info.start + info.removed != oldCount {
						if deletePrevious {
							Deque.moveInitialize(preMappedSourceRange: (info.start + info.removed)..<oldCount, postMappedDestinationRange: (info.start + info.inserted)..<info.newCount, sourceHeader: headerPtr, sourceBody: bodyPtr, destinationBody: newBody)
						} else {
							Deque.copyInitialize(preMappedSourceRange: (info.start + info.removed)..<oldCount, postMappedDestinationRange: (info.start + info.inserted)..<info.newCount, sourceHeader: headerPtr, sourceBody: bodyPtr, destinationBody: newBody)
						}
					}
				}
				
				// Make sure the old buffer doesn't deinitialize when it deallocates.
				if deletePrevious {
					headerPtr.pointee.count = 0
				}
			}
			
			if info.inserted > 0 {
				newBuffer.withUnsafeMutablePointerToElements { newBody in
					#if swift(>=3.1)
						let umbp = UnsafeMutableBufferPointer(start: newBody.advanced(by: info.start), count: info.inserted)
						_ = umbp.initialize(from: newElements)
					#else
						// Insert the new subrange
						newBody.advanced(by: info.start).initialize(from: newElements)
					#endif
				}
			}
			
			buffer = newBuffer
		}
	}
	
	/// Implemetation of the RangeReplaceableCollection function. Internally
	/// implemented using either mutateWithoutReallocate or reallocateAndMutate.
	mutating func replaceSubrange<C>(_ subrange: Range<Int>, with newElements: C) where C: Collection, C.Iterator.Element == T {
		precondition(subrange.lowerBound >= 0, "Subrange lowerBound is negative")
		
		if isKnownUniquelyReferenced(&buffer), let b = buffer {
			b.withUnsafeMutablePointers { headerPtr, bodyPtr in
				let info = DequeMutationInfo2(subrange: subrange, previousCount: headerPtr.pointee.count, insertedCount: numericCast(newElements.count))
				if info.newCount <= headerPtr.pointee.capacity && (info.newCount < minCapacity || info.newCount > headerPtr.pointee.capacity / downsizeTriggerFactor) {
					Deque.mutateWithoutReallocate(info: info, elements: newElements, header: headerPtr, body: bodyPtr)
				} else {
					reallocateAndMutate(info: info, elements: newElements, header: headerPtr, body: bodyPtr, deletePrevious: true)
				}
			}
		} else if let b = buffer {
			b.withUnsafeMutablePointers { headerPtr, bodyPtr in
				let info = DequeMutationInfo2(subrange: subrange, previousCount: headerPtr.pointee.count, insertedCount: numericCast(newElements.count))
				reallocateAndMutate(info: info, elements: newElements, header: headerPtr, body: bodyPtr, deletePrevious: false)
			}
		} else {
			let info = DequeMutationInfo2(subrange: subrange, previousCount: 0, insertedCount: numericCast(newElements.count))
			reallocateAndMutate(info: info, elements: newElements, header: nil, body: nil, deletePrevious: true)
		}
	}
}

// Internal state for the Deque
private struct DequeHeader {
	var offset: Int
	var count: Int
	var capacity: Int
	
	// Translate from preMapped to postMapped indices.
	//
	// "preMapped" refer to the indices exposed by this type (zero based, contiguous), and "postMapped" refers to internal offsets within the buffer (not necessarily zero based and may wrap around).
	//
	// Since "postMapped" indices are not necessarily contiguous, two separate, contiguous ranges are returned. Both `startIndex` and `endIndex` in the `high` range will equal the `endIndex` in the `low` range if the range specified by `inRange` is continuous after mapping.
	func splitRangeIndices(inRange: CountableRange<Int>) -> (low: CountableRange<Int>, high: CountableRange<Int>) {
		let limit = capacity - offset
		if inRange.startIndex >= limit {
			return (low: (inRange.startIndex - limit)..<(inRange.endIndex - limit), high: (inRange.endIndex - limit)..<(inRange.endIndex - limit))
		} else if inRange.endIndex > limit {
			return (low: (inRange.startIndex + offset)..<capacity, high: 0..<(inRange.endIndex - limit))
		}
		return (low: (inRange.startIndex + offset)..<(inRange.endIndex + offset), high: (inRange.endIndex + offset)..<(inRange.endIndex + offset))
	}
	
}

// Private type used to communicate parameters between replaceSubrange<C>(_:with:)
// and reallocateAndMutate or mutateWithoutReallocate
private struct DequeMutationInfo2 {
	let start: Int
	let removed: Int
	let inserted: Int
	let newCount: Int
	
	init(subrange: Range<Int>, previousCount: Int, insertedCount: Int) {
		precondition(subrange.upperBound <= previousCount, "Subrange upperBound is out of range")
		
		self.start = subrange.lowerBound
		self.removed = subrange.count
		self.inserted = insertedCount
		self.newCount = previousCount - self.removed + self.inserted
	}
}

// Private reimplementation of function with same name from stdlib/public/core/BuiltIn.swift
private func roundUp(_ offset: UInt, toAlignment alignment: Int) -> UInt {
	let x = offset + UInt(bitPattern: alignment) &- 1
	return x & ~(UInt(bitPattern: alignment) &- 1)
}

// Private reimplementation of definition from stdlib/public/SwiftShims/HeapObject.h
private struct HeapObject {
	let metadata: Int = 0
	let strongRefCount: UInt32 = 0
	let weakRefCount: UInt32 = 0
}

// An implementation of DequeBuffer using ManagedBufferPointer to allocate the
// storage and then using raw pointer offsets into self to access contents
// (avoiding the ManagedBufferPointer accessors which are a performance problem
// in Swift 3).
private final class DequeBuffer<T>: ManagedBuffer<DequeHeader, T> {
	#if true
		private static var headerOffset: Int {
			return Int(roundUp(UInt(MemoryLayout<HeapObject>.size), toAlignment: MemoryLayout<DequeHeader>.alignment))
		}
		
		private static var elementOffset: Int {
			return Int(roundUp(UInt(headerOffset) + UInt(MemoryLayout<DequeHeader>.size), toAlignment: MemoryLayout<T>.alignment))
		}
		
		private var bodyPtr: UnsafeMutablePointer<T> {
			return Unmanaged<DequeBuffer<T>>.passUnretained(self).toOpaque().advanced(by: DequeBuffer<T>.elementOffset).assumingMemoryBound(to: T.self)
		}
		
		private var headerPtr: UnsafeMutablePointer<DequeHeader> {
			return Unmanaged<DequeBuffer<T>>.passUnretained(self).toOpaque().advanced(by: DequeBuffer<T>.headerOffset).assumingMemoryBound(to: DequeHeader.self)
		}
	#endif
	
	deinit {
		#if true
			// We need to assert this in case some of our dirty assumptions stop being true
			assert(ManagedBufferPointer<DequeHeader, T>(unsafeBufferObject: self).withUnsafeMutablePointers { (header, body) in
				self.headerPtr == header && self.bodyPtr == body
			})
			
			let splitRange = headerPtr.pointee.splitRangeIndices(inRange: 0..<headerPtr.pointee.count)
			bodyPtr.advanced(by: splitRange.low.startIndex).deinitialize(count: splitRange.low.count)
			bodyPtr.advanced(by: splitRange.high.startIndex).deinitialize(count: splitRange.high.count)
		#else
			withUnsafeMutablePointers { headerPtr, bodyPtr in
				let splitRange = headerPtr.pointee.splitRangeIndices(inRange: 0..<headerPtr.pointee.count)
				bodyPtr.advanced(by: splitRange.low.startIndex).deinitialize(count: splitRange.low.count)
				bodyPtr.advanced(by: splitRange.high.startIndex).deinitialize(count: splitRange.high.count)
			}
		#endif
	}
}

import Foundation

extension DispatchSource {
	// An overload of timer that immediately sets the handler and schedules the timer
	class func singleTimer(interval: DispatchTimeInterval, leeway: DispatchTimeInterval = .nanoseconds(0), queue: DispatchQueue, handler: @escaping () -> Void) -> DispatchSourceTimer {
		let result = DispatchSource.makeTimerSource(queue: queue)
		result.setEventHandler(handler: handler)
		#if swift(>=4)
			result.schedule(deadline: DispatchTime.now() + interval, leeway: leeway)
		#else
			result.scheduleOneshot(deadline: DispatchTime.now() + interval, leeway: leeway)
		#endif
		result.resume()
		return result
	}
	
	// An overload of timer that always uses the default global queue (because it is intended to enter the appropriate mutex as a separate step) and passes a user-supplied Int to the handler function to allow ignoring callbacks if cancelled or rescheduled before mutex acquisition.
	class func singleTimer<T>(parameter: T, interval: DispatchTimeInterval, leeway: DispatchTimeInterval = .nanoseconds(0), queue: DispatchQueue = DispatchQueue.global(), handler: @escaping (T) -> Void) -> DispatchSourceTimer {
		let result = DispatchSource.makeTimerSource(queue: queue)
		result.scheduleOneshot(parameter: parameter, interval: interval, leeway: leeway, handler: handler)
		result.resume()
		return result
	}
	
	// An overload of timer that immediately sets the handler and schedules the timer
	class func repeatingTimer(interval: DispatchTimeInterval, leeway: DispatchTimeInterval = .nanoseconds(0), queue: DispatchQueue = DispatchQueue.global(), handler: @escaping () -> Void) -> DispatchSourceTimer {
		let result = DispatchSource.makeTimerSource(queue: queue)
		result.setEventHandler(handler: handler)
		#if swift(>=4)
			result.schedule(deadline: DispatchTime.now() + interval, repeating: interval, leeway: leeway)
		#else
			result.scheduleRepeating(deadline: DispatchTime.now() + interval, interval: interval, leeway: leeway)
		#endif
		result.resume()
		return result
	}
	
	// An overload of timer that always uses the default global queue (because it is intended to enter the appropriate mutex as a separate step) and passes a user-supplied Int to the handler function to allow ignoring callbacks if cancelled or rescheduled before mutex acquisition.
	class func repeatingTimer<T>(parameter: T, interval: DispatchTimeInterval, leeway: DispatchTimeInterval = .nanoseconds(0), queue: DispatchQueue = DispatchQueue.global(), handler: @escaping (T) -> Void) -> DispatchSourceTimer {
		let result = DispatchSource.makeTimerSource(queue: queue)
		result.scheduleRepeating(parameter: parameter, interval: interval, leeway: leeway, handler: handler)
		result.resume()
		return result
	}
}

extension DispatchSourceTimer {
	// An overload of scheduleOneshot that updates the handler function with a new user-supplied parameter when it changes the expiry deadline
	func scheduleOneshot<T>(parameter: T, interval: DispatchTimeInterval, leeway: DispatchTimeInterval = .nanoseconds(0), handler: @escaping (T) -> Void) {
		suspend()
		setEventHandler { handler(parameter) }
		#if swift(>=4)
			schedule(deadline: DispatchTime.now() + interval, leeway: leeway)
		#else
			scheduleOneshot(deadline: DispatchTime.now() + interval, leeway: leeway)
		#endif
		resume()
	}
	
	// An overload of scheduleOneshot that updates the handler function with a new user-supplied parameter when it changes the expiry deadline
	func scheduleRepeating<T>(parameter: T, interval: DispatchTimeInterval, leeway: DispatchTimeInterval = .nanoseconds(0), handler: @escaping (T) -> Void) {
		suspend()
		setEventHandler { handler(parameter) }
		#if swift(>=4)
			schedule(deadline: DispatchTime.now() + interval, repeating: interval, leeway: leeway)
		#else
			scheduleRepeating(deadline: DispatchTime.now() + interval, interval: interval, leeway: leeway)
		#endif
		resume()
	}
}

extension DispatchTime {
	func since(_ previous: DispatchTime) -> DispatchTimeInterval {
		return .nanoseconds(Int(uptimeNanoseconds - previous.uptimeNanoseconds))
	}
}

extension DispatchTimeInterval {
	static func interval(_ seconds: TimeInterval) -> DispatchTimeInterval {
		if MemoryLayout<Int>.size < 8 {
			return .milliseconds(Int(seconds * Double(NSEC_PER_SEC / NSEC_PER_MSEC)))
		} else {
			return .nanoseconds(Int(seconds * Double(NSEC_PER_SEC)))
		}
	}
	
	var seconds: Double {
		#if swift (>=3.2)
			switch self {
			case .seconds(let t): return Double(t)
			case .milliseconds(let t): return (Double(NSEC_PER_MSEC) / Double(NSEC_PER_SEC)) * Double(t)
			case .microseconds(let t): return (Double(NSEC_PER_USEC) / Double(NSEC_PER_SEC)) * Double(t)
			case .nanoseconds(let t): return (1.0 / Double(NSEC_PER_SEC)) * Double(t)
			case .never: return Double.infinity
			#if swift (>=5)
				default: fatalError("Unknown case")
			#endif
			}
		#else
			switch self {
			case .seconds(let t): return Double(t)
			case .milliseconds(let t): return (Double(NSEC_PER_MSEC) / Double(NSEC_PER_SEC)) * Double(t)
			case .microseconds(let t): return (Double(NSEC_PER_USEC) / Double(NSEC_PER_SEC)) * Double(t)
			case .nanoseconds(let t): return (1.0 / Double(NSEC_PER_SEC)) * Double(t)
			}
		#endif
	}
	
	var nanoseconds: Int64 {
		#if swift (>=3.2)
			switch self {
			case .seconds(let t): return Int64(NSEC_PER_SEC) * Int64(t)
			case .milliseconds(let t): return Int64(NSEC_PER_MSEC) * Int64(t)
			case .microseconds(let t): return Int64(NSEC_PER_USEC) * Int64(t)
			case .nanoseconds(let t): return Int64(t)
			case .never: return Int64.max
			#if swift (>=5)
				default: fatalError("Unknown case")
			#endif
			}
		#else
			switch self {
			case .seconds(let t): return Int64(NSEC_PER_SEC) * Int64(t)
			case .milliseconds(let t): return Int64(NSEC_PER_MSEC) * Int64(t)
			case .microseconds(let t): return Int64(NSEC_PER_USEC) * Int64(t)
			case .nanoseconds(let t): return Int64(t)
			}
		#endif
	}
}

import Foundation

/// `Exec` is a representation of an arbitrary execution context and offers the ability to interrogate properties of the execution context or to invoke blocks within the context in a number of different ways. The base enum implements the three most common types of execution context in Swift. Switching over these pre-defined cases enables the caller to perform appropriate optimizations (e.g. avoiding calling `invoke` on Exec.direct).
///
/// - direct: the context will directly call any supplied block with no other action taken
/// - main: the context will invoke on the main thread, preferring synchronous invocation where possible.
/// - queue: the context will invoke on a DispatchQueue with details descrbied in the `ExecutionType`
/// - custom: a `CustomExecutionContext` handles all interrogation and invoking
enum Exec {
	/// Invoked directly from the caller's context
	case direct
	
	/// Invoked on the main thread, directly if the current thread is the main thread, otherwise asynchronously (unless invokeSync is used)
	case main
	
	/// Invoked using a Dispatch Queue
	case queue(DispatchQueue, ExecutionType)
	
	/// Invoked using the wrapped existential.
	case custom(CustomExecutionContext)
}

extension Exec {
	/// If this context is concurrent, returns a serialization around this context, otherwise returns this context.
	func serialized() -> Exec {
		return self.type.isConcurrent ? Exec.custom(SerializingContext(concurrentContext: self)) : self
	}
	
	/// Invoked on the main thread, always asynchronously (unless invokeSync is used)
	static var mainAsync: Exec {
		return .queue(.main, .threadAsync { Thread.isMainThread })
	}
	
	/// Invoked asynchronously in the global queue with QOS_CLASS_DEFAULT priority
	static var global: Exec {
		return .queue(.global(), .concurrentAsync)
	}
	
	/// Invoked asynchronously in the global queue with QOS_CLASS_DEFAULT priority
	static func global(qos: DispatchQoS.QoSClass) -> Exec {
		return .queue(.global(qos: qos), .concurrentAsync)
	}
	
	/// Invoked asynchronously in the global queue with QOS_CLASS_USER_INTERACTIVE priority
	static var interactive: Exec {
		return .queue(.global(qos: .userInteractive), .concurrentAsync)
	}
	
	/// Invoked asynchronously in the global queue with QOS_CLASS_USER_INITIATED priority
	static var user: Exec {
		return .queue(.global(qos: .userInitiated), .concurrentAsync)
	}
	
	/// Invoked asynchronously in the global queue with QOS_CLASS_UTILITY priority
	static var utility: Exec {
		return .queue(.global(qos: .utility), .concurrentAsync)
	}
	
	/// Invoked asynchronously in the global queue with QOS_CLASS_BACKGROUND priority
	static var background: Exec {
		return .queue(.global(qos: .background), .concurrentAsync)
	}
	
	/// Constructs an Exec.queue configured as an ExecutionType.recursiveMutex
	static func syncQueue(qos: DispatchQoS.QoSClass = .default) -> Exec {
		return Exec.queue(DispatchQueue(label: ""), ExecutionType.mutex)
	}
	
	/// Constructs an Exec.queue configured as an ExecutionType.recursiveAsync
	static func asyncQueue(qos: DispatchQoS.QoSClass = .default) -> Exec {
		return Exec.queue(DispatchQueue(label: ""), ExecutionType.serialAsync)
	}
}

extension Exec: CustomExecutionContext {
	/// A description about how functions will be invoked on an execution context.
	var type: ExecutionType {
		switch self {
		case .direct: return .immediate
		case .main: return .thread { Thread.isMainThread }
		case .custom(let c): return c.type
		case .queue(_, let t): return t
		}
	}
	
	/// Run `execute` normally on the execution context
	func invoke(_ execute: @escaping () -> Void) {
		switch self {
		case .direct: execute()
		case .main where Thread.isMainThread: execute()
		case .main: DispatchQueue.main.async(execute: execute)
		case .queue(_, .thread(let test)) where test(): execute()
		case .queue(_, .recursiveMutex(let test)) where test(): execute()
		case .queue(let q, let t) where t.isImmediateInCurrentContext: q.sync(execute: execute)
		case .queue(let q, _): q.async(execute: execute)
		case .custom(let c): c.invoke(execute)
		}
	}
	
	/// Run `execute` asynchronously on the execution context
	func invokeAsync(_ execute: @escaping () -> Void) {
		switch self {
		case .direct: DispatchQueue.global().async(execute: execute)
		case .custom(let c): c.invokeAsync(execute)
		case .main: DispatchQueue.main.async(execute: execute)
		case .queue(let q, _): q.async(execute: execute)
		}
	}
	
	/// Run `execute` on the execution context but don't return from this function until the provided function is complete.
	func invokeSync<Result>(_ execute: () throws -> Result) rethrows -> Result {
		switch self {
		case .direct: return try execute()
		case .main where Thread.isMainThread: return try execute()
		case .main: return try DispatchQueue.main.sync(execute: execute)
		case .queue(_, .thread(let test)) where test(): return try execute()
		case .queue(_, .threadAsync(let test)) where test(): return try execute()
		case .queue(_, .recursiveMutex(let test)) where test(): return try execute()
		case .queue(let q, _): return try withoutActuallyEscaping(execute) { e in try q.sync(execute: e) }
		case .custom(let c): return try c.invokeSync(execute)
		}
	}
	
	/// Invokes in a global concurrent context. This context can be used to safely "escape" self.
	///
	/// - Parameter qos: the QoSClass for the new async context. If `nil`, the QoSClass will be derived from the properties of `self`
	/// - Returns: a context that is asynchronous and can be used to escape self
	func relativeAsync(qos: DispatchQoS.QoSClass? = nil) -> Exec {
		switch self {
		case .custom(let c): return c.relativeAsync(qos: qos)
		case .main: return Exec.global(qos: .userInteractive)
		case .queue(let q, _): return Exec.global(qos: q.qos.qosClass)
		case .direct: return Exec.global
		}
	}
	
	private var timerQueue: DispatchQueue {
		switch self {
		case .direct: return DispatchQueue.global()
		case .main: return DispatchQueue.main
		case .queue(let q, _): return q
		case .custom: fatalError()
		}
	}
	
	/// Run `execute` on the execution context after `interval` (plus `leeway`) unless the returned `Lifetime` is cancelled or released before running occurs.
	func singleTimer(interval: DispatchTimeInterval, leeway: DispatchTimeInterval = .nanoseconds(0), handler: @escaping () -> Void) -> Lifetime {
		if case .custom(let c) = self {
			return c.singleTimer(interval: interval, leeway: leeway, handler: handler)
		}
		return DispatchSource.singleTimer(interval: interval, leeway: leeway, queue: timerQueue, handler: handler) as! DispatchSource
	}
	
	/// Run `execute` on the execution context after `interval` (plus `leeway`), passing the `parameter` value as an argument, unless the returned `Lifetime` is cancelled or released before running occurs.
	func singleTimer<T>(parameter: T, interval: DispatchTimeInterval, leeway: DispatchTimeInterval = .nanoseconds(0), handler: @escaping (T) -> Void) -> Lifetime {
		if case .custom(let c) = self {
			return c.singleTimer(parameter: parameter, interval: interval, leeway: leeway, handler: handler)
		}
		return DispatchSource.singleTimer(parameter: parameter, interval: interval, leeway: leeway, queue: timerQueue, handler: handler) as! DispatchSource
	}
	
	/// Run `execute` on the execution context after `interval` (plus `leeway`), and again every `interval` (within a `leeway` margin of error) unless the returned `Lifetime` is cancelled or released before running occurs.
	func periodicTimer(interval: DispatchTimeInterval, leeway: DispatchTimeInterval = .nanoseconds(0), handler: @escaping () -> Void) -> Lifetime {
		if case .custom(let c) = self {
			return c.periodicTimer(interval: interval, leeway: leeway, handler: handler)
		}
		return DispatchSource.repeatingTimer(interval: interval, leeway: leeway, queue: timerQueue, handler: handler) as! DispatchSource
	}
	
	/// Run `execute` on the execution context after `interval` (plus `leeway`), passing the `parameter` value as an argument, and again every `interval` (within a `leeway` margin of error) unless the returned `Lifetime` is cancelled or released before running occurs.
	func periodicTimer<T>(parameter: T, interval: DispatchTimeInterval, leeway: DispatchTimeInterval = .nanoseconds(0), handler: @escaping (T) -> Void) -> Lifetime {
		if case .custom(let c) = self {
			return c.periodicTimer(parameter: parameter, interval: interval, leeway: leeway, handler: handler)
		}
		return DispatchSource.repeatingTimer(parameter: parameter, interval: interval, leeway: leeway, queue: timerQueue, handler: handler) as! DispatchSource
	}
	
	/// Gets a timestamp representing the host uptime the in the current context
	func timestamp() -> DispatchTime {
		if case .custom(let c) = self {
			return c.timestamp()
		}
		return DispatchTime.now()
	}
}

extension Exec {
	@available(*, deprecated, message: "Use invokeSync instead")
	func invokeAndWait(_ execute: @escaping () -> Void) {
		_ = invokeSync(execute)
	}
	
	@available(*, deprecated, message:"Values returned from this may be misleading. Perform your own switch to precisely get the information you need.")
	var dispatchQueue: DispatchQueue {
		switch self {
		case .direct, .custom: return DispatchQueue.global()
		case .main: return DispatchQueue.main
		case .queue(let q, _): return q
		}
	}
}

/// Describes 7 key execution context types. The six most common exist as a pair between a sychronous and asynchronous version:
///  * immediate and concurrentAsync
///  * mutex and serialAsync
///  * thread and threadAsync
/// With the final context being an additional variation on mutex:
///  * recursiveMutex
///
/// This list of of execution context types should *not* be considered exhaustive so in general, it is better to interrogate the boolean properties in which you're interested.
/// These properties are currently:
///  * isImmediate[InCurrentContext|Always]
///  * isReentrant
///  * isConcurrent
enum ExecutionType {
	/// This execution type models a simple function invocation.
	///	* completes before `invoke` returns (immediate)
	///   * applies no mutex so nested calls to `invoke` will succeed (reentrant)
	///   * will let parallel calls run at the same time (concurrent)
	///   * invocation always inherits the caller's context (nest always)
	/// e.g. directly calling
	case immediate
	
	/// This execution type models a global concurrent work pool.
	///	* runs outside the current context and might not complete before `invoke` returns (asynchronous)
	///   * involves no mutex so nested calls to `invokeSync` are permitted (reentrant)
	///   * will let parallel calls run at the same time (concurrent)
	///   * normally async but `invokeSync` is invoked from the calling context (sync nests)
	/// e.g. DispatchQueue.global().async
	case concurrentAsync
	
	/// This execution type models a scoped non-recursive mutex.
	///	* completes before `invoke` returns (immediate)
	///   * applies a non-reentrant mutex so nested calls to `invoke` will deadlock (non-reentrant)
	///   * will serialize parallel calls to run one at a time (serial)
	///   * invocation always inherits the caller's context (nest always)
	/// e.g. dispatchQueue.sync
	case mutex
	
	/// This execution type models a scoped recursive mutex. The associated test function returns `true` if the `invoke` or `invokeSync` function can be elided (replaced by direct invocation, since the current context is known to be inside the mutex).
	///	* completes before `invoke` returns (immediate)
	///   * applies a mutex but a nested `invoke` will safely re-enter the mutex (reentrant)
	///   * will serialize parallel calls to run one at a time (serial)
	///   * invocation always inherits the caller's context (nest always)
	/// e.g. NSRecursiveLock.lock(before:)
	case recursiveMutex(() -> Bool)
	
	/// This execution type models a thread. The associated test function returns `true` if the `invoke` or `invokeSync` function can be elided (replaced by direct invocation, since the current context is known to be inside the thread).
	///	* if test function returns true, then `invoke` is immediate in the current context, otherwise asychronous (immediate/asynchronous)
	///   * nested calls to `invoke` are permitted since they will simply be run immediately (reentrant)
	///   * will serialize parallel calls to run one at a time (serial)
	///   * invocation only inherits the caller's context if test function returns true in current context (nest thread)
	/// e.g. `if Thread.isMainThread { /* do work */ } else { DispatchQueue.main.async { /* do work */ }`
	case thread(() -> Bool)
	
	/// This execution type models a thread on which work is typically performed asynchronously. The associated test function returns `true` if the `invoke` or `invokeSync` function can be elided (replaced by direct invocation, since the current context is known to be inside the thread).
	///	* `invoke` is always asynchronous (asynchronous)
	///   * detects when it is already on the current thread so nested calls to `invokeSync` will not deadlock (reentrant)
	///   * will serialize parallel calls to run one at a time (serial)
	///   * normally async but `invokeSync` nests if already on its thread (nest syncThread)
	/// e.g. DispatchQueue.main.async
	case threadAsync(() -> Bool)
	
	/// This execution type models an asynchronous resource that lacks any synchronous access.
	///	* runs outside the current context and might not complete before `invoke` returns (asynchronous)
	///   * applies a non-reentrant mutex so nested calls to `invokeSync` will deadlock (non-reentrant)
	///   * will serialize parallel calls to run one at a time (serial)
	///   * invocation never inherits the caller's context (nest no)
	/// e.g. a serial resource that offers a `performAsync(_:() -> Void)` but doesn't offer a `performSync(_:() -> Void)`
	case serialAsync
}

extension ExecutionType {
	/// Returns true if a block executed with `invoke` is guaranteed to complete before `invoke` returns in the current context.
	/// The inverse of this value is "isAsyncInCurrentContext".
	///
	/// NOTE: this property runs a function for case `.thread` to see if the current thread is the target thread. Any change queue/thread may break the guarantee (the name "thread" is representative-only and might not refer to a literal thread).
	var isImmediateInCurrentContext: Bool {
		switch self {
		case .immediate, .mutex, .recursiveMutex: return true
		case .thread(let isCurrent): return isCurrent()
		case .serialAsync, .concurrentAsync, .threadAsync: return false
		}
	}
	
	/// Inverse of `isImmediateInCurrentContext`
	var isAsyncInCurrentContext: Bool { return !isImmediateInCurrentContext }
	
	/// Returns true if a block executed with `invoke` is always guaranteed to complete before `invoke` returns.
	/// The inverse of this value is "isPotentiallyAsync"
	var isImmediateAlways: Bool {
		switch self {
		case .immediate, .mutex, .recursiveMutex: return true
		case .thread, .serialAsync, .concurrentAsync, .threadAsync: return false
		}
	}
	
	/// Inverse of `isImmediateAlways`
	var isPotentiallyAsync: Bool { return !isImmediateInCurrentContext }
	
	/// Returns true if calling `invoke` or `invokeSync` within an executed block will succeed (not deadlock).
	/// The inverse of this value is "non-reentrant"
	var isReentrant: Bool {
		switch self {
		case .immediate, .recursiveMutex, .thread, .threadAsync, .concurrentAsync: return true
		case .mutex, .serialAsync: return false
		}
	}
	
	/// Inverse of `isReentrant`
	var isNonReentrant: Bool { return !isReentrant }
	
	/// Returns true if calling `invoke` simultaneously on separate threads may result in simultaneous execution.
	/// The inverse of this value is "serial"
	var isConcurrent: Bool {
		switch self {
		case .immediate, .concurrentAsync: return true
		case .mutex, .recursiveMutex, .serialAsync, .thread, .threadAsync: return false
		}
	}
	
	/// Inverse of `isConcurrent`
	var isSerial: Bool { return !isConcurrent }
}


import Foundation

enum Few<T> {
	case none
	case single(T)
	case array(Array<T>)
}

extension Few: Collection {
	func index(after i: Int) -> Int {
		return i + 1
	}
	
	var count: Int {
		switch self {
		case .none: return 0
		case .single: return 1
		case .array(let a): return a.count
		}
	}
	
	var startIndex: Int {
		return 0
	}
	
	var endIndex: Int {
		switch self {
		case .none: return 0
		case .single: return 1
		case .array(let a): return a.endIndex
		}
	}
	
	subscript(key: Int) -> T {
		switch self {
		case .none: fatalError()
		case .single(let value): return value
		case .array(let a): return a[key]
		}
	}
}

import Foundation

/// A wrapper around key-value observing so that you:
///	1. don't need to implement `observeValue` yourself, you can instead handle changes in a closure
///	2. you get a `CallbackReason` for each change which includes `valueChanged`, `pathChanged`, `sourceDeleted`.
///	3. observation is automatically cancelled if you release the KeyValueObserver or the source is released
///
/// While Swift 4 offers an `observe(...) -> NSKeyValueObservation` function which avoids the need for (1), this wrapper continues to offer an advantage on points (2) and (3).
///
/// A majority of the complexity in this class comes from the fact that we turn key-value observing on keyPaths into a series of chained KeyValueObservers that we manage ourselves. This gives us more information when things change but we're re-implementing a number of things that Cococa key-value observing normally gives us for free. Generally in this class, anything involving the `tailPath` is managing observations of the path.
///
/// THREAD SAFETY:
/// This class is memory safe even when observations are triggered concurrently from different threads.
/// Do note though that while all changes are registered under the mutex, callbacks are invoked *outside* the mutex, so it is possible for callbacks to be invoked in a different order than the internal synchronized order.
/// In general, this shouldn't be a problem (since key-value observing is not itself synchronized so there *isn't* an authoritative ordering). However, this may cause unexpected behavior if you invoke `cancel` on this class. If you `cancel` the `KeyValueObserver` while it is concurrently processing changes on another thread, this might result in callback invocations occurring *after* the call to `cancel`. This will only happen if the changes associated with those callbacks were received *before* the `cancel` - it's just the callback that's getting invoked later.
@available(*, deprecated, message:"Use Swift's native KeyPath and observe(_:, options:, changeHandler:) instead")
class KeyValueObserver: NSObject, Lifetime {
	typealias Callback = (_ change: [NSKeyValueChangeKey: Any], _ reason: CallbackReason) -> Void

	// This is the user-supplied callback function
	private var callback: Callback?
	
	// When observing a keyPath, we use a separate KeyValueObserver for each component of the path. The `tailObserver` is the `KeyValueObserver` for the *next* element in the path.
	private var tailObserver: KeyValueObserver?
	
	// This is the key that we're observing on `source`
	private let key: String
	
	// This is any path beyond the key.
	private let tailPath: String?
	
	// This is the set of options passed on construction
	private let options: NSKeyValueObservingOptions
	
	// Used to ensure memory safety for the callback and tailObserver.
	private let mutex = DispatchQueue(label: "")
	
	// Our "deletionBlock" is called to notify us that the source is being deallocated (so we can remove the key value observation before a warning is logged) and this happens during the source's "objc_destructinstance" function. At this point, a `weak` var will be `nil` and an `unowned` will trigger a `_swift_abortRetainUnowned` failure.
	// So we're left with `Unmanaged`. Careful cancellation before the source is deallocated is necessary to ensure we don't access an invalid memory location.
	private let source: Unmanaged<NSObject>
	
	/// The `CallbackReason` explains the location in the path where the change occurred.
	///
	/// - valueChanged: the observed value changed
	/// - pathChanged: one of the connected elements in the path changed
	/// - sourceDeleted: the observed source was deallocated
	/// - cancelled: will never be sent
	enum CallbackReason {
		case valueChanged
		case pathChanged
		case sourceDeleted
		case cancelled
	}
	
	/// Establish the key value observing.
	///
	/// - Parameters:
	///   - source: object on which there's a property we wish to observe
	///   - keyPath: a key or keyPath identifying the property we wish to observe
	///   - options: same as for the normal `addObserver` method
	///   - callback: will be invoked on each change with the change dictionary and the change reason
	init(source: NSObject, keyPath: String, options: NSKeyValueObservingOptions = NSKeyValueObservingOptions.new.union(NSKeyValueObservingOptions.initial), callback: @escaping Callback) {
		self.callback = callback
		self.source = Unmanaged.passUnretained(source)
		self.options = options
		
		// Look for "." indicating a key path
		var range = keyPath.range(of: ".")
		
		// If we have a collection operator, consider the next path component as part of this key
		if let r = range, keyPath.hasPrefix("@") {
			range = keyPath.range(of: ".", range: keyPath.index(after: r.lowerBound)..<keyPath.endIndex, locale: nil)
		}
		
		// Set the key and tailPath based on whether we detected multiple path components
		if let r = range {
			#if swift(>=4)
				self.key = String(keyPath[..<r.lowerBound])
				self.tailPath = String(keyPath[keyPath.index(after: r.lowerBound)...])
			#else
				self.key = keyPath.substring(to: r.lowerBound)
				self.tailPath = keyPath.substring(from: keyPath.index(after: r.lowerBound))
			#endif
		} else {
			self.key = keyPath
			
			// If we're observing a weak property, add an observer on self to the source to detect when it may be set to nil without going through the property setter
			var p: String? = nil
			if let propertyName = keyPath.cString(using: String.Encoding.utf8) {
				let property = class_getProperty(type(of: source), propertyName)
				// Look for both the "id" and "weak" attributes.
				if let prop = property, let attributes = property_getAttributes(prop), let attrsString = String(validatingUTF8: attributes)?.components(separatedBy: ","), attrsString.filter({ $0.hasPrefix("T@") || $0 == "W" }).count == 2 {
					p = "self"
				}
			}
			self.tailPath = p
		}
		
		super.init()
		
		// Detect if the source is deleted
		let deletionBlock = OnDelete { [weak self] in self?.cancel(.sourceDeleted) }
		objc_setAssociatedObject(source, Unmanaged.passUnretained(self).toOpaque(), deletionBlock, objc_AssociationPolicy.OBJC_ASSOCIATION_RETAIN)
		
		// Start observing the source
		if key != "self" {
			var currentOptions = options
			if !isObservingTail {
				currentOptions = NSKeyValueObservingOptions.new.union(options.intersection(NSKeyValueObservingOptions.prior))
			}
			
			source.addObserver(self, forKeyPath: key, options: currentOptions, context: Unmanaged.passUnretained(self).toOpaque())
		}
		
		// Start observing the value of the source
		if tailPath != nil {
			updateTailObserver(onValue: source.value(forKeyPath: self.key) as? NSObject, isInitial: true)
		}
	}
	
	deinit {
		cancel()
	}
	
	// This method is called when the key path between the source and the observed property changes. This will recursively create KeyValueObservers along the path.
	//
	// Mutex notes: Method must be called from *INSIDE* mutex (although, it must be *OUTSIDE* the tailObserver's mutex).
	private func updateTailObserver(onValue: NSObject?, isInitial: Bool) {
		tailObserver?.cancel()
		tailObserver = nil
		
		if let _ = self.callback, let tp = tailPath, let currentValue = onValue {
			let currentOptions = isInitial ? self.options : self.options.subtracting(NSKeyValueObservingOptions.initial)
			self.tailObserver = KeyValueObserver(source: currentValue, keyPath: tp, options: currentOptions, callback: self.tailCallback)
		}
	}
	
	// This method is called from the `tailObserver` (representing a change in the key path, not the observed property)
	//
	// Mutex notes: Method is called *OUTSIDE* mutex since it is used as a callback function for the `tailObserver`
	private func tailCallback(_ change: [NSKeyValueChangeKey: Any], reason: CallbackReason) {
		switch reason {
		case .cancelled:
			return
		case .sourceDeleted:
			let c = mutex.sync(execute: { () -> Callback? in
				updateTailObserver(onValue: nil, isInitial: false)
				return self.callback
			})
			c?(change, self.isObservingTail ? .valueChanged : .pathChanged)
		default:
			let c = mutex.sync { self.callback }
			c?(change, reason)
		}
	}
	
	// The method returns `false` if there are subsequent `KeyValueObserver`s observing part of the path between us and the observed property and `true` if we are directly observing the property.
	//
	// Mutex notes: Safe for invocation in or out of mutex
	private var isObservingTail: Bool {
		return tailPath == nil || tailPath == "self"
	}
	
	// Weak properties need `self` observed, as well as the property, to correctly detect changes.
	//
	// Mutex notes: Safe for invocation in or out of mutex
	private var needsWeakTailObserver: Bool {
		return tailPath == "self"
	}
	
	// Accessor for the observed property value. This will correctly get the value from the end of the key path if we are using a tailObserver.
	//
	// Mutex notes: Method must be called from *INSIDE* mutex.
	private func sourceValue() -> Any? {
		if let t = tailObserver, !isObservingTail {
			return t.sourceValue()
		} else {
			return source.takeUnretainedValue().value(forKeyPath: key)
		}
	}
	
	// If we're observing a key path, then we need to update our chain of KeyValueObservers when part of the path changes. This starts that process from the change point.
	//
	// Mutex notes: Method must be called from *INSIDE* mutex.
	private func updateTailObserverGivenChangeDictionary(change: [NSKeyValueChangeKey: Any]) {
		if let newValue = change[NSKeyValueChangeKey.newKey] as? NSObject {
			let value: NSObject? = newValue == NSNull() ? nil : newValue
			updateTailObserver(onValue: value, isInitial: false)
		} else {
			updateTailObserver(onValue: sourceValue() as? NSObject, isInitial: false)
		}
	}
	
	// Implementation of standard key-value observing method.
	override func observeValue(forKeyPath keyPath: String?, of object: Any?, change: [NSKeyValueChangeKey: Any]?, context: UnsafeMutableRawPointer?) {
		if context != Unmanaged.passUnretained(self).toOpaque() {
			super.observeValue(forKeyPath: keyPath, of: object, change: change, context: context)
		}
		
		guard let c = change else {
			assertionFailure("Expected change dictionary")
			return
		}
		
		if self.isObservingTail {
			let cb = mutex.sync { () -> Callback? in
				if needsWeakTailObserver {
					updateTailObserverGivenChangeDictionary(change: c)
				}
				return self.callback
			}
			cb?(c, .valueChanged)
			
		} else {
			let tuple = mutex.sync { () -> (Callback, [NSKeyValueChangeKey: Any])? in
				var transmittedChange: [NSKeyValueChangeKey: Any] = [:]
				if !options.intersection(NSKeyValueObservingOptions.old).isEmpty {
					transmittedChange[NSKeyValueChangeKey.oldKey] = tailObserver?.sourceValue()
				}
				if let _ = c[NSKeyValueChangeKey.notificationIsPriorKey] as? Bool {
					transmittedChange[NSKeyValueChangeKey.notificationIsPriorKey] = true
				}
				updateTailObserverGivenChangeDictionary(change: c)
				if !options.intersection(NSKeyValueObservingOptions.new).isEmpty {
					transmittedChange[NSKeyValueChangeKey.newKey] = tailObserver?.sourceValue()
				}
				if let c = callback {
					return (c, transmittedChange)
				}
				return nil
			}
			if let (cb, tc) = tuple {
				cb(tc, .pathChanged)
			}
		}
	}
	
	/// Stop observing.
	func cancel() {
		cancel(.cancelled)
	}
	
	// Mutex notes: Method is called *OUTSIDE* mutex
	private func cancel(_ reason: CallbackReason) {
		let cb = mutex.sync { () -> Callback? in
			guard let c = callback else { return nil }
			
			// Flag as inactive
			callback = nil
			
			// Remove the observations from this object
			if key != "self" {
				source.takeUnretainedValue().removeObserver(self, forKeyPath: key, context: Unmanaged.passUnretained(self).toOpaque())
			}
			
			// Cancel the OnDelete object
			let unknown = objc_getAssociatedObject(source, Unmanaged.passUnretained(self).toOpaque())
			if let deletionObject = unknown as? OnDelete {
				deletionObject.cancel()
			}

			// And clear the associated object
			objc_setAssociatedObject(source, Unmanaged.passUnretained(self).toOpaque(), nil, objc_AssociationPolicy.OBJC_ASSOCIATION_RETAIN);
			
			// Remove tail observers
			updateTailObserver(onValue: nil, isInitial: false)
			
			// Send notifications
			return reason != .cancelled ? c : nil
		}
		
		cb?([:], reason)
	}
}

import Foundation

/// This protocol exists to keep alive and terminate-at-will asynchronous and ongoing tasks. It is an
/// implementation of the "Disposable" pattern.
///
/// While conformance to this protocol requires just one function, conforming to this protocol also signals three important traits:
///    1. instances manage an underlying resource
///	 2. the resource will last until one the first of the following end-conditions occurs:
///        a. The resource terminates on its own
///        b. All references to the Lifetime instance are released
///        c. The `cancel()` function is invoked
///
/// ideally, as well:
///
///    3. no further effects or actions of any kind will occur after the first end-condition is registered in the
///       resource's context, no further messages or notifications sent or received, no resurrection possible
///    4. any subsequent end conditions after the first are safe and have no effect
///    5. if Self is a reference type, `cancel` should be explicitly invoked on deinit
///    6. `cancel` should invoke `cancel` on any owned child Lifetime instances
///
/// Examples of violations of the last 4 points exist be should be kept rare.
protocol Lifetime {
	/// Immediately set the resource managed by this instance to an "end-of-life" state.
	/// This a mutating method and should be called only in executation contexts where changing `self` is threadsafe.
	mutating func cancel()
}

typealias Cancellable = Lifetime

/// An array of Lifetime that conforms to Lifetime. Note that a conditional conformance on Array can't properly conform
// to Lifetime since it would permit adding new lifetimes after the aggregate was cancelled.
class AggregateLifetime: Lifetime {
	private var lifetimes: [Lifetime]?
	init(lifetimes: [Lifetime] = []) {
		self.lifetimes = lifetimes
	}
	func cancel() {
		if var ls = lifetimes {
			for i in ls.indices {
				ls[i].cancel()
			}
			lifetimes = nil
		}
	}
	static func +=(left: AggregateLifetime, right: Lifetime) {
		left.lifetimes?.append(right)
	}
	deinit {
		cancel()
	}
}

#if os(Linux)
	import Glibc
#else
	import Darwin
#endif

/// A basic mutex protocol that requires nothing more than "performing work inside the mutex".
protocol ScopedMutex {
	/// Perform work inside the mutex
	func sync<R>(execute work: () throws -> R) rethrows -> R

	/// Perform work inside the mutex, returning immediately if the mutex is in-use
	func trySync<R>(execute work: () throws -> R) rethrows -> R?
}

/// A more specific kind of mutex that assume an underlying primitive and unbalanced lock/trylock/unlock operators
protocol RawMutex: ScopedMutex {
	associatedtype MutexPrimitive

	var underlyingMutex: MutexPrimitive { get set }

	func unbalancedLock()
	func unbalancedTryLock() -> Bool
	func unbalancedUnlock()
}

extension RawMutex {
	func sync<R>(execute work: () throws -> R) rethrows -> R {
		unbalancedLock()
		defer { unbalancedUnlock() }
		return try work()
	}
	func trySync<R>(execute work: () throws -> R) rethrows -> R? {
		guard unbalancedTryLock() else { return nil }
		defer { unbalancedUnlock() }
		return try work()
	}
}

/// A basic wrapper around the "NORMAL" and "RECURSIVE" `pthread_mutex_t` (a general purpose mutex). This type is a "class" type to take advantage of the "deinit" method and prevent accidental copying of the `pthread_mutex_t`.
final class PThreadMutex: RawMutex {
	typealias MutexPrimitive = pthread_mutex_t

	// Non-recursive "PTHREAD_MUTEX_NORMAL" and recursive "PTHREAD_MUTEX_RECURSIVE" mutex types.
	enum PThreadMutexType {
		case normal
		case recursive
	}

	var underlyingMutex = pthread_mutex_t()
	
	/// Default constructs as ".Normal" or ".Recursive" on request.
	init(type: PThreadMutexType = .normal) {
		var attr = pthread_mutexattr_t()
		guard pthread_mutexattr_init(&attr) == 0 else {
			preconditionFailure()
		}
		switch type {
		case .normal:
			pthread_mutexattr_settype(&attr, PTHREAD_MUTEX_NORMAL)
		case .recursive:
			pthread_mutexattr_settype(&attr, PTHREAD_MUTEX_RECURSIVE)
		}
		guard pthread_mutex_init(&underlyingMutex, &attr) == 0 else {
			preconditionFailure()
		}
		pthread_mutexattr_destroy(&attr)
	}
	
	deinit {
		pthread_mutex_destroy(&underlyingMutex)
	}
	
	func unbalancedLock() {
		pthread_mutex_lock(&underlyingMutex)
	}
	
	func unbalancedTryLock() -> Bool {
		return pthread_mutex_trylock(&underlyingMutex) == 0
	}
	
	func unbalancedUnlock() {
		pthread_mutex_unlock(&underlyingMutex)
	}
}

/// A basic wrapper around `os_unfair_lock` (a non-FIFO, high performance lock that offers safety against priority inversion). This type is a "class" type to prevent accidental copying of the `os_unfair_lock`.
@available(OSX 10.12, iOS 10, tvOS 10, *)
final class UnfairLock: RawMutex {
	typealias MutexPrimitive = os_unfair_lock
	
	init() {
	}
	
	/// Exposed as an "unsafe" property so non-scoped patterns can be implemented, if required.
	var underlyingMutex = os_unfair_lock()
	
	func unbalancedLock() {
		os_unfair_lock_lock(&underlyingMutex)
	}
	
	func unbalancedTryLock() -> Bool {
		return os_unfair_lock_trylock(&underlyingMutex)
	}
	
	func unbalancedUnlock() {
		os_unfair_lock_unlock(&underlyingMutex)
	}
}

import Swift

final class OnDelete: Lifetime {
	var block: (() -> Void)?
	
	init(_ b: @escaping () -> Void) {
		block = b
	}
	
	func invalidate() {
		block = nil
	}
	
	func cancel() {
		block?()
		block = nil
	}
	
	var isValid: Bool {
		return block != nil
	}
	
	deinit {
		cancel()
	}
}

import Foundation

#if !swift(>=4.2)
	protocol RandomNumberGenerator {
		mutating func next() -> UInt64
	}
	struct SystemRandomNumberGenerator: RandomNumberGenerator {
		init() {}
		mutating func next() -> UInt64 {
			var value: UInt64 = 0
			arc4random_buf(&value, MemoryLayout<UInt64>.size)
			return value
		}
	}
#endif

protocol RandomGenerator: RandomNumberGenerator {
	mutating func randomize(buffer: UnsafeMutableRawBufferPointer)
}

extension RandomGenerator {
	mutating func randomize<Value>(value: inout Value) {
		withUnsafeMutablePointer(to: &value) { ptr in
			self.randomize(buffer: UnsafeMutableRawBufferPointer(start: ptr, count: MemoryLayout<Value>.size))
		}
	}
}

struct DevRandom: RandomGenerator {
	class FileDescriptor {
		let value: CInt
		init() {
			value = open("/dev/urandom", O_RDONLY)
			precondition(value >= 0)
		}
		deinit {
			close(value)
		}
	}
	
	let fd: FileDescriptor
	init() {
		fd = FileDescriptor()
	}
	
	mutating func randomize(buffer: UnsafeMutableRawBufferPointer) {
		let result = read(fd.value, buffer.baseAddress, buffer.count)
		precondition(result == buffer.count)
	}
	
	mutating func next() -> UInt64 {
		var bits: UInt64 = 0
		withUnsafeMutablePointer(to: &bits) { ptr in
			self.randomize(buffer: UnsafeMutableRawBufferPointer(start: ptr, count: MemoryLayout<UInt64>.size))
		}
		return bits
	}
}

struct Xoshiro: RandomNumberGenerator {
	typealias StateType = (UInt64, UInt64, UInt64, UInt64)

	private var state: StateType = (0, 0, 0, 0)

	init() {
		var dr = DevRandom()
		dr.randomize(value: &state)
	}
	
	init(seed: StateType) {
		self.state = seed
	}
	
	mutating func next() -> UInt64 {
		// Derived from domain implementation of xoshiro256** here:
		// http://xoshiro.di.unimi.it
		// by David Blackman and Sebastiano Vigna
		let x = state.1 &* 5
		let result = ((x &<< 7) | (x &>> 57)) &* 9
		let t = state.1 &<< 17
		state.2 ^= state.0
		state.3 ^= state.1
		state.1 ^= state.2
		state.0 ^= state.3
		state.2 ^= t
		state.3 = (state.3 &<< 45) | (state.3 &>> 19)
		return result
	}
}

struct MersenneTwister: RandomNumberGenerator {
	// 312 words of storage is 13 x 6 x 4
	private typealias StateType = (
		UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64,
		UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64,
		UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64,
		UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64,
		UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64,
		UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64,

		UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64,
		UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64,
		UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64,
		UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64,
		UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64,
		UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64,

		UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64,
		UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64,
		UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64,
		UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64,
		UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64,
		UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64,

		UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64,
		UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64,
		UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64,
		UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64,
		UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64,
		UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64, UInt64
	)
	
	private var state_internal: StateType = (
		0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
		0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
		0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
		0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
		0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
		0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,

		0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
		0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
		0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
		0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
		0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
		0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,

		0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
		0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
		0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
		0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
		0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
		0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,

		0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
		0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
		0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
		0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
		0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
		0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0
	)
	private var index: Int
	private static let stateCount: Int = 312
	
	init() {
		var dr = DevRandom()
		dr.randomize(value: &state_internal)
		index = MersenneTwister.stateCount
	}
	
	init(seed: UInt64) {
		index = MersenneTwister.stateCount
		withUnsafeMutablePointer(to: &state_internal) { $0.withMemoryRebound(to: UInt64.self, capacity: MersenneTwister.stateCount) { state in
			state[0] = seed
			for i in 1..<MersenneTwister.stateCount {
				state[i] = 6364136223846793005 &* (state[i &- 1] ^ (state[i &- 1] >> 62)) &+ UInt64(i)
			}
		} }
	}

	mutating func next() -> UInt64 {
		if index == MersenneTwister.stateCount {
			withUnsafeMutablePointer(to: &state_internal) { $0.withMemoryRebound(to: UInt64.self, capacity: MersenneTwister.stateCount) { state in
				let n = MersenneTwister.stateCount
				let m = n / 2
				let a: UInt64 = 0xB5026F5AA96619E9
				let lowerMask: UInt64 = (1 << 31) - 1
				let upperMask: UInt64 = ~lowerMask
				var (i, j, stateM) = (0, m, state[m])
				repeat {
					let x1 = (state[i] & upperMask) | (state[i &+ 1] & lowerMask)
					state[i] = state[i &+ m] ^ (x1 >> 1) ^ ((state[i &+ 1] & 1) &* a)
					let x2 = (state[j] & upperMask) | (state[j &+ 1] & lowerMask)
					state[j] = state[j &- m] ^ (x2 >> 1) ^ ((state[j &+ 1] & 1) &* a)
					(i, j) = (i &+ 1, j &+ 1)
				} while i != m &- 1
				
				let x3 = (state[m &- 1] & upperMask) | (stateM & lowerMask)
				state[m &- 1] = state[n &- 1] ^ (x3 >> 1) ^ ((stateM & 1) &* a)
				let x4 = (state[n &- 1] & upperMask) | (state[0] & lowerMask)
				state[n &- 1] = state[m &- 1] ^ (x4 >> 1) ^ ((state[0] & 1) &* a)
			} }
			
			index = 0
		}
		
		var result = withUnsafePointer(to: &state_internal) { $0.withMemoryRebound(to: UInt64.self, capacity: MersenneTwister.stateCount) { ptr in
			return ptr[index]
		} }
		index = index &+ 1

		result ^= (result >> 29) & 0x5555555555555555
		result ^= (result << 17) & 0x71D67FFFEDA60000
		result ^= (result << 37) & 0xFFF7EEE000000000
		result ^= result >> 43

		return result
	}
}

import Foundation

/// Either a Success value or an Failure error
extension Result {
	/// Convenience tester/getter for the value
	var value: Success? {
		switch self {
		case .success(let s): return s
		case .failure: return nil
		}
	}
	
	/// Convenience tester/getter for the error
	var error: Failure? {
		switch self {
		case .success: return nil
		case .failure(let f): return f
		}
	}

	/// Test whether the result is an error.
	var isSuccess: Bool {
		return !isFailure
	}

	/// Test whether the result is an error.
	var isFailure: Bool {
		switch self {
		case .success: return false
		case .failure: return true
		}
	}
}

extension Result where Failure == Swift.Error {
	/// Chains another Result to this one. In the event that this Result is a .Success, the provided transformer closure is used to transform the value into another value (of a potentially new type) and a new Result is made from that value. In the event that this Result is a .Failure, the next Result will have the same error as this one.
	func mapThrows<U>(_ transform: (Success) throws -> U) -> Result<U, Failure> {
		switch self {
		case .success(let val): return Result<U, Failure> { try transform(val) }
		case .failure(let e): return .failure(e)
		}
	}
}

import Swift

/// A type for representing the different possible failure conditions when using ScalarScanner
enum ScalarScannerError: Error {
	/// The scalar at the specified index doesn't match the expected grammar
	case unexpected(at: Int)
	
	/// Expected `wanted` at offset `at`
	case matchFailed(wanted: String, at: Int)
	
	/// Expected numerals at offset `at`
	case expectedInt(at: Int)
	
	/// Attempted to read `count` scalars from position `at` but hit the end of the sequence
	case endedPrematurely(count: Int, at: Int)
	
	/// Unable to find search patter `wanted` at or after `after` in the sequence
	case searchFailed(wanted: String, after: Int)
}

extension UnicodeScalar {
	/// Tests if the scalar is within a range
	func isInRange(_ range: ClosedRange<UnicodeScalar>) -> Bool {
		return range.contains(self)
	}
	
	/// Tests if the scalar is a plain ASCII digit
	var isDigit: Bool {
		return ("0"..."9").contains(self)
	}
	
	/// Tests if the scalar is a plain ASCII English alphabet lowercase letter
	var isLower: Bool {
		return ("a"..."z").contains(self)
	}

	/// Tests if the scalar is a plain ASCII English alphabet uppercase letter
	var isUpper: Bool {
		return ("A"..."Z").contains(self)
	}

	/// Tests if the scalar is a plain ASCII English alphabet letter
	var isLetter: Bool {
		return isLower || isUpper
	}
}

/// A structure for traversing a `String.UnicodeScalarView`.
///
/// **UNICODE WARNING**: this struct ignores all Unicode combining rules and parses each scalar individually. The rules for parsing must allow combined characters to be parsed separately or better yet, forbid combining characters at critical parse locations. If your data structure does not include these types of rule then you should be iterating over the `Character` elements in a `String` rather than using this struct.
struct ScalarScanner<C: Collection> where C.Iterator.Element == UnicodeScalar {
	/// The underlying storage
	let scalars: C
	
	/// Current scanning index
	var index: C.Index
	
	/// Number of scalars consumed up to `index` (since String.UnicodeScalarView.Index is not a RandomAccessIndex, this makes determining the position *much* easier)
	var consumed: Int
	
	/// Construct from a String.UnicodeScalarView and a context value
	init(scalars: C) {
		self.scalars = scalars
		self.index = self.scalars.startIndex
		self.consumed = 0
	}
	
	/// Sets the index back to the beginning and clears the consumed count
	mutating func reset() {
		index = scalars.startIndex
		consumed = 0
	}
	
	/// Throw if the scalars at the current `index` don't match the scalars in `scalars`. Advance the `index` to the end of the match.
	/// WARNING: `string` is used purely for its `unicodeScalars` property and matching is purely based on direct scalar comparison (no decomposition or normalization is performed).
	mutating func match(string: String) throws {
		let (newIndex, newConsumed) = try string.unicodeScalars.reduce((index: index, count: 0)) { (tuple: (index: C.Index, count: Int), scalar: UnicodeScalar) in
			if tuple.index == self.scalars.endIndex || scalar != self.scalars[tuple.index] {
				throw ScalarScannerError.matchFailed(wanted: string, at: consumed)
			}
			return (index: self.scalars.index(after: tuple.index), count: tuple.count + 1)
		}
		index = newIndex
		consumed += newConsumed
	}
	
	/// Throw if the next scalar at the current `index` fails to match the next scalar in `scalars`. Advance the `index` to the end of the match.
	mutating func match(scalar: UnicodeScalar) throws {
		if index == scalars.endIndex || scalars[index] != scalar {
			throw ScalarScannerError.matchFailed(wanted: String(scalar), at: consumed)
		}
		index = self.scalars.index(after: index)
		consumed += 1
	}
	
	/// Throw if the next scalar at the current `index` fails to match the next scalar in `scalars`. Advance the `index` to the end of the match.
	mutating func match(where test: (UnicodeScalar) -> Bool) throws {
		if index == scalars.endIndex || !test(scalars[index]) {
			try withoutActuallyEscaping(test) { t in
				throw ScalarScannerError.matchFailed(wanted: String(describing: t), at: consumed)
			}
		}
		index = self.scalars.index(after: index)
		consumed += 1
	}
	
	/// Throw if the scalars at the current `index` don't match the scalars in `value`. Advance the `index` to the end of the match.
	mutating func read(where test: (UnicodeScalar) -> Bool) throws -> UnicodeScalar {
		if index == scalars.endIndex || !test(scalars[index]) {
			try withoutActuallyEscaping(test) { t in
				throw ScalarScannerError.matchFailed(wanted: String(describing: t), at: consumed)
			}
		}
		let s = scalars[index]
		index = self.scalars.index(after: index)
		consumed += 1
		return s
	}

	/// Consume scalars from the contained collection, up to but not including the first instance of `scalar` found. `index` is advanced to immediately before `scalar`. Returns all scalars consumed prior to `scalar` as a `String`. Throws if `scalar` is never found.
	mutating func readUntil(scalar: UnicodeScalar) throws -> String {
		var i = index
		let previousConsumed = consumed
		try skipUntil(scalar: scalar)
		
		var result = ""
		result.reserveCapacity(consumed - previousConsumed)
		while i != index {
			result.unicodeScalars.append(scalars[i])
			i = scalars.index(after: i)
		}
		
		return result
	}
	
	/// Consume scalars from the contained collection, up to but not including the first instance of `string` found. `index` is advanced to immediately before `string`. Returns all scalars consumed prior to `string` as a `String`. Throws if `string` is never found.
	/// WARNING: `string` is used purely for its `unicodeScalars` property and matching is purely based on direct scalar comparison (no decomposition or normalization is performed).
	mutating func readUntil(string: String) throws -> String {
		var i = index
		let previousConsumed = consumed
		try skipUntil(string: string)
		
		var result = ""
		result.reserveCapacity(consumed - previousConsumed)
		while i != index {
			result.unicodeScalars.append(scalars[i])
			i = scalars.index(after: i)
		}
		
		return result
	}
	
	/// Consume scalars from the contained collection, up to but not including the first instance of any character in `set` found. `index` is advanced to immediately before `string`. Returns all scalars consumed prior to `string` as a `String`. Throws if no matching characters are ever found.
	mutating func readUntil(set inSet: Set<UnicodeScalar>) throws -> String {
		var i = index
		let previousConsumed = consumed
		try skipUntil(set: inSet)
		
		var result = ""
		result.reserveCapacity(consumed - previousConsumed)
		while i != index {
			result.unicodeScalars.append(scalars[i])
			i = scalars.index(after: i)
		}
		
		return result
	}
	
	/// Peeks at the scalar at the current `index`, testing it with function `f`. If `f` returns `true`, the scalar is appended to a `String` and the `index` increased. The `String` is returned at the end.
	mutating func readWhile(true test: (UnicodeScalar) -> Bool) -> String {
		var string = ""
		while index != scalars.endIndex {
			if !test(scalars[index]) {
				break
			}
			string.unicodeScalars.append(scalars[index])
			index = self.scalars.index(after: index)
			consumed += 1
		}
		return string
	}
	
	/// Repeatedly peeks at the scalar at the current `index`, testing it with function `f`. If `f` returns `true`, the `index` increased. If `false`, the function returns.
	mutating func skipWhile(true test: (UnicodeScalar) -> Bool) {
		while index != scalars.endIndex {
			if !test(scalars[index]) {
				return
			}
			index = self.scalars.index(after: index)
			consumed += 1
		}
	}
	
	/// Consume scalars from the contained collection, up to but not including the first instance of `scalar` found. `index` is advanced to immediately before `scalar`. Throws if `scalar` is never found.
	mutating func skipUntil(scalar: UnicodeScalar) throws {
		var i = index
		var c = 0
		while i != scalars.endIndex && scalars[i] != scalar {
			i = self.scalars.index(after: i)
			c += 1
		}
		if i == scalars.endIndex {
			throw ScalarScannerError.searchFailed(wanted: String(scalar), after: consumed)
		}
		index = i
		consumed += c
	}
	
	/// Consume scalars from the contained collection, up to but not including the first instance of any scalar from `set` is found. `index` is advanced to immediately before `scalar`. Throws if `scalar` is never found.
	mutating func skipUntil(set inSet: Set<UnicodeScalar>) throws {
		var i = index
		var c = 0
		while i != scalars.endIndex && !inSet.contains(scalars[i]) {
			i = self.scalars.index(after: i)
			c += 1
		}
		if i == scalars.endIndex {
			throw ScalarScannerError.searchFailed(wanted: "One of: \(inSet.sorted())", after: consumed)
		}
		index = i
		consumed += c
	}
	
	/// Consume scalars from the contained collection, up to but not including the first instance of `string` found. `index` is advanced to immediately before `string`. Throws if `string` is never found.
	/// WARNING: `string` is used purely for its `unicodeScalars` property and matching is purely based on direct scalar comparison (no decomposition or normalization is performed).
	mutating func skipUntil(string: String) throws {
		let match = string.unicodeScalars
		guard let first = match.first else { return }
		if match.count == 1 {
			return try skipUntil(scalar: first)
		}
		var i = index
		var j = index
		var c = 0
		var d = 0
		let remainder = match[match.index(after: match.startIndex)..<match.endIndex]
		outerLoop: repeat {
			while scalars[i] != first {
				if i == scalars.endIndex {
					throw ScalarScannerError.searchFailed(wanted: String(match), after: consumed)
				}
				i = self.scalars.index(after: i)
				c += 1
				
				// Track the last index and consume count before hitting the match
				j = i
				d = c
			}
			i = self.scalars.index(after: i)
			c += 1
			for s in remainder {
				if i == self.scalars.endIndex {
					throw ScalarScannerError.searchFailed(wanted: String(match), after: consumed)
				}
				if scalars[i] != s {
					continue outerLoop
				}
				i = self.scalars.index(after: i)
				c += 1
			}
			break
		} while true
		index = j
		consumed += d
	}
	
	/// Attempt to advance the `index` by count, returning `false` and `index` unchanged if `index` would advance past the end, otherwise returns `true` and `index` is advanced.
	mutating func skip(count: Int = 1) throws {
		if count == 1 && index != scalars.endIndex {
			index = scalars.index(after: index)
			consumed += 1
		} else {
			var i = index
			var c = count
			while c > 0 {
				if i == scalars.endIndex {
					throw ScalarScannerError.endedPrematurely(count: count, at: consumed)
				}
				i = self.scalars.index(after: i)
				c -= 1
			}
			index = i
			consumed += count
		}
	}
	
	/// Attempt to advance the `index` by count, returning `false` and `index` unchanged if `index` would advance past the end, otherwise returns `true` and `index` is advanced.
	mutating func backtrack(count: Int = 1) throws {
		if count <= consumed {
			if count == 1 {
				index = scalars.index(index, offsetBy: -1)
				consumed -= 1
			} else {
				let limit = consumed - count
				while consumed != limit {
					index = scalars.index(index, offsetBy: -1)
					consumed -= 1
				}
			}
		} else {
			throw ScalarScannerError.endedPrematurely(count: -count, at: consumed)
		}
	}
	
	/// Returns all content after the current `index`. `index` is advanced to the end.
	mutating func remainder() -> String {
		var string: String = ""
		while index != scalars.endIndex {
			string.unicodeScalars.append(scalars[index])
			index = scalars.index(after: index)
			consumed += 1
		}
		return string
	}
	
	/// If the next scalars after the current `index` match `scalars`, advance over them and return `true`, otherwise, leave `index` unchanged and return `false`.
	/// WARNING: `string` is used purely for its `unicodeScalars` property and matching is purely based on direct scalar comparison (no decomposition or normalization is performed).
	mutating func conditional(string: String) -> Bool {
		var i = index
		var c = 0
		for s in string.unicodeScalars {
			if i == scalars.endIndex || s != scalars[i] {
				return false
			}
			i = self.scalars.index(after: i)
			c += 1
		}
		index = i
		consumed += c
		return true
	}
	
	/// If the next scalar after the current `index` match `scalars`, advance over it and return `true`, otherwise, leave `index` unchanged and return `false`.
	mutating func conditional(scalar: UnicodeScalar) -> Bool {
		if index == scalars.endIndex || scalar != scalars[index] {
			return false
		}
		index = self.scalars.index(after: index)
		consumed += 1
		return true
	}
	
	/// If the next scalar after the current `index` match `value`, advance over it and return `true`, otherwise, leave `index` unchanged and return `false`.
	mutating func conditional(where test: (UnicodeScalar) -> Bool) -> UnicodeScalar? {
		if index == scalars.endIndex || !test(scalars[index]) {
			return nil
		}
		let s = scalars[index]
		index = self.scalars.index(after: index)
		consumed += 1
		return s
	}
	
	/// If the `index` is at the end, throw, otherwise, return the next scalar at the current `index` without advancing `index`.
	func requirePeek() throws -> UnicodeScalar {
		if index == scalars.endIndex {
			throw ScalarScannerError.endedPrematurely(count: 1, at: consumed)
		}
		return scalars[index]
	}
	
	/// If `index` + `ahead` is within bounds, return the scalar at that location, otherwise return `nil`. The `index` will not be changed in any case.
	func peek(skipCount: Int = 0) -> UnicodeScalar? {
		var i = index
		var c = skipCount
		while c > 0 && i != scalars.endIndex {
			i = self.scalars.index(after: i)
			c -= 1
		}
		if i == scalars.endIndex {
			return nil
		}
		return scalars[i]
	}
	
	/// If the `index` is at the end, throw, otherwise, return the next scalar at the current `index`, advancing `index` by one.
	mutating func readScalar() throws -> UnicodeScalar {
		if index == scalars.endIndex {
			throw ScalarScannerError.endedPrematurely(count: 1, at: consumed)
		}
		let result = scalars[index]
		index = self.scalars.index(after: index)
		consumed += 1
		return result
	}
	
	/// Throws if scalar at the current `index` is not in the range `"0"` to `"9"`. Consume scalars `"0"` to `"9"` until a scalar outside that range is encountered. Return the integer representation of the value scanned, interpreted as a base 10 integer. `index` is advanced to the end of the number.
	mutating func readInt() throws -> Int {
		let result = conditionalInt()
		guard let r = result else {
			throw ScalarScannerError.expectedInt(at: consumed)
		}
		return r
	}
	
	/// Throws if scalar at the current `index` is not in the range `"0"` to `"9"`. Consume scalars `"0"` to `"9"` until a scalar outside that range is encountered. Return the integer representation of the value scanned, interpreted as a base 10 integer. `index` is advanced to the end of the number.
	mutating func conditionalInt() -> Int? {
		var result = 0
		var i = index
		var c = 0
		while i != scalars.endIndex && scalars[i].isDigit {
			let digit = Int(scalars[i].value - UnicodeScalar("0").value)
			// Avoid overflow
			if (Int.max - digit) / 10 < result {
				return nil
			}
			result = result * 10 + digit
			i = self.scalars.index(after: i)
			c += 1
		}
		if i == index {
			return nil
		}
		index = i
		consumed += c
		return result
	}
	
	/// Consume and return `count` scalars. `index` will be advanced by count. Throws if end of `scalars` occurs before consuming `count` scalars.
	mutating func readScalars(count: Int) throws -> String {
		var result = String()
		result.reserveCapacity(count)
		var i = index
		for _ in 0..<count {
			if i == scalars.endIndex {
				throw ScalarScannerError.endedPrematurely(count: count, at: consumed)
			}
			result.unicodeScalars.append(scalars[i])
			i = self.scalars.index(after: i)
		}
		index = i
		consumed += count
		return result
	}
	
	/// Returns a throwable error capturing the current scanner progress point.
	func unexpectedError() -> ScalarScannerError {
		return ScalarScannerError.unexpected(at: consumed)
	}
	
	var isAtEnd: Bool {
		return index == scalars.endIndex
	}
}

import Foundation

/// An `ExecutionContext` wraps a mutex around calls invoked by an underlying execution context. The effect is to serialize concurrent contexts (immediate or concurrent).
struct SerializingContext: CustomExecutionContext {
	let underlying: Exec
	let mutex = PThreadMutex(type: .recursive)
	
	init(concurrentContext: Exec) {
		underlying = concurrentContext
	}
	
	var type: ExecutionType {
		switch underlying.type {
		case .immediate: return .mutex
		case .concurrentAsync: return .serialAsync
		case .mutex, .recursiveMutex, .thread, .threadAsync, .serialAsync: return underlying.type
		}
	}
	
	func invoke(_ execute: @escaping () -> Void) {
		if case .direct = underlying {
			mutex.sync(execute: execute)
		} else {
			underlying.invoke { [mutex] in mutex.sync(execute: execute) }
		}
	}
	
	func invokeAsync(_ execute: @escaping () -> Void) {
		underlying.invokeAsync { [mutex] in mutex.sync(execute: execute) }
	}
	
	@available(*, deprecated, message: "Use invokeSync instead")
	func invokeAndWait(_ execute: @escaping () -> Void) {
		_ = invokeSync(execute)
	}
	
	func invokeSync<Return>(_ execute: () throws -> Return) rethrows -> Return {
		if case .direct = underlying {
			return try mutex.sync(execute: execute)
		} else {
			return try underlying.invokeSync { [mutex] () throws -> Return in try mutex.sync(execute: execute) }
		}
	}
	
	/// Run `execute` on the execution context after `interval` (plus `leeway`) unless the returned `Lifetime` is cancelled or released before running occurs.
	func singleTimer(interval: DispatchTimeInterval, leeway: DispatchTimeInterval, handler: @escaping () -> Void) -> Lifetime {
		return mutex.sync { () -> Lifetime in
			let wrapper = MutexWrappedLifetime(mutex: mutex)
			let lifetime = underlying.singleTimer(interval: interval, leeway: leeway) { [weak wrapper] in
				if let w = wrapper {
					w.mutex.sync {
						// Need to perform this double check since the timer may have been cancelled/changed before we managed to enter the mutex
						if w.lifetime != nil {
							handler()
						}
					}
				}
			}
			wrapper.lifetime = lifetime
			return wrapper
		}
	}
	
	/// Run `execute` on the execution context after `interval` (plus `leeway`), passing the `parameter` value as an argument, unless the returned `Lifetime` is cancelled or released before running occurs.
	func singleTimer<T>(parameter: T, interval: DispatchTimeInterval, leeway: DispatchTimeInterval, handler: @escaping (T) -> Void) -> Lifetime {
		return mutex.sync { () -> Lifetime in
			let wrapper = MutexWrappedLifetime(mutex: mutex)
			let lifetime = underlying.singleTimer(parameter: parameter, interval: interval, leeway: leeway) { [weak wrapper] p in
				if let w = wrapper {
					w.mutex.sync {
						// Need to perform this double check since the timer may have been cancelled/changed before we managed to enter the mutex
						if w.lifetime != nil {
							handler(p)
						}
					}
				}
			}
			wrapper.lifetime = lifetime
			return wrapper
		}
	}
	
	/// Run `execute` on the execution context after `interval` (plus `leeway`), and again every `interval` (within a `leeway` margin of error) unless the returned `Lifetime` is cancelled or released before running occurs.
	func periodicTimer(interval: DispatchTimeInterval, leeway: DispatchTimeInterval, handler: @escaping () -> Void) -> Lifetime {
		return mutex.sync { () -> Lifetime in
			let wrapper = MutexWrappedLifetime(mutex: mutex)
			let lifetime = underlying.periodicTimer(interval: interval, leeway: leeway) { [weak wrapper] in
				if let w = wrapper {
					w.mutex.sync {
						// Need to perform this double check since the timer may have been cancelled/changed before we managed to enter the mutex
						if w.lifetime != nil {
							handler()
						}
					}
				}
			}
			wrapper.lifetime = lifetime
			return wrapper
		}
	}
	
	/// Run `execute` on the execution context after `interval` (plus `leeway`), passing the `parameter` value as an argument, and again every `interval` (within a `leeway` margin of error) unless the returned `Lifetime` is cancelled or released before running occurs.
	func periodicTimer<T>(parameter: T, interval: DispatchTimeInterval, leeway: DispatchTimeInterval, handler: @escaping (T) -> Void) -> Lifetime {
		return mutex.sync { () -> Lifetime in
			let wrapper = MutexWrappedLifetime(mutex: mutex)
			let lifetime = underlying.periodicTimer(parameter: parameter, interval: interval, leeway: leeway) { [weak wrapper] p in
				if let w = wrapper {
					w.mutex.sync {
						if w.lifetime != nil {
							handler(p)
						}
					}
				}
			}
			wrapper.lifetime = lifetime
			return wrapper
		}
	}
	
	/// Gets a timestamp representing the host uptime the in the current context
	func timestamp() -> DispatchTime {
		return underlying.timestamp()
	}
}

/// A wrapper around Lifetime that applies a mutex on the cancel operation.
/// This is a class so that `SerializingContext` can pass it weakly to the timer closure, avoiding having the timer keep itself alive.
private class MutexWrappedLifetime: Lifetime {
	var lifetime: Lifetime? = nil
	let mutex: PThreadMutex
	
	init(mutex: PThreadMutex) {
		self.mutex = mutex
	}
	
	func cancel() {
		mutex.sync {
			lifetime?.cancel()
			lifetime = nil
		}
	}
	
	deinit {
		cancel()
	}
}

import Foundation

/// A "static"-only namespace around a series of functions that operate on buffers returned from the `Darwin.sysctl` function
struct Sysctl {
	/// Possible errors.
	enum Error: Swift.Error {
		case unknown
		case malformedUTF8
		case invalidSize
		case posixError(POSIXErrorCode)
	}
	
	/// Access the raw data for an array of sysctl identifiers.
	static func data(for keys: [Int32]) throws -> [Int8] {
		return try keys.withUnsafeBufferPointer() { keysPointer throws -> [Int8] in
			// Preflight the request to get the required data size
			var requiredSize = 0
			let preFlightResult = Darwin.sysctl(UnsafeMutablePointer<Int32>(mutating: keysPointer.baseAddress), UInt32(keys.count), nil, &requiredSize, nil, 0)
			if preFlightResult != 0 {
				throw POSIXErrorCode(rawValue: errno).map {
					print($0.rawValue)
					return Error.posixError($0)
				} ?? Error.unknown
			}
			
			// Run the actual request with an appropriately sized array buffer
			let data = Array<Int8>(repeating: 0, count: requiredSize)
			let result = data.withUnsafeBufferPointer() { dataBuffer -> Int32 in
				return Darwin.sysctl(UnsafeMutablePointer<Int32>(mutating: keysPointer.baseAddress), UInt32(keys.count), UnsafeMutableRawPointer(mutating: dataBuffer.baseAddress), &requiredSize, nil, 0)
			}
			if result != 0 {
				throw POSIXErrorCode(rawValue: errno).map { Error.posixError($0) } ?? Error.unknown
			}
			
			return data
		}
	}

	/// Convert a sysctl name string like "hw.memsize" to the array of `sysctl` identifiers (e.g. [CTL_HW, HW_MEMSIZE])
	static func keys(for name: String) throws -> [Int32] {
		var keysBufferSize = Int(CTL_MAXNAME)
		var keysBuffer = Array<Int32>(repeating: 0, count: keysBufferSize)
		try keysBuffer.withUnsafeMutableBufferPointer { (lbp: inout UnsafeMutableBufferPointer<Int32>) throws in
			try name.withCString { (nbp: UnsafePointer<Int8>) throws in
				guard sysctlnametomib(nbp, lbp.baseAddress, &keysBufferSize) == 0 else {
					throw POSIXErrorCode(rawValue: errno).map { Error.posixError($0) } ?? Error.unknown
				}
			}
		}
		if keysBuffer.count > keysBufferSize {
			keysBuffer.removeSubrange(keysBufferSize..<keysBuffer.count)
		}
		return keysBuffer
	}

	/// Invoke `sysctl` with an array of identifers, interpreting the returned buffer as the specified type. This function will throw `Error.invalidSize` if the size of buffer returned from `sysctl` fails to match the size of `T`.
	static func value<T>(ofType: T.Type, forKeys keys: [Int32]) throws -> T {
		let buffer = try data(for: keys)
		if buffer.count != MemoryLayout<T>.size {
			throw Error.invalidSize
		}
		return try buffer.withUnsafeBufferPointer() { bufferPtr throws -> T in
			guard let baseAddress = bufferPtr.baseAddress else { throw Error.unknown }
			return baseAddress.withMemoryRebound(to: T.self, capacity: 1) { $0.pointee }
		}
	}
	
	/// Invoke `sysctl` with an array of identifers, interpreting the returned buffer as the specified type. This function will throw `Error.invalidSize` if the size of buffer returned from `sysctl` fails to match the size of `T`.
	static func value<T>(ofType type: T.Type, forKeys keys: Int32...) throws -> T {
		return try value(ofType: type, forKeys: keys)
	}
	
	/// Invoke `sysctl` with the specified name, interpreting the returned buffer as the specified type. This function will throw `Error.invalidSize` if the size of buffer returned from `sysctl` fails to match the size of `T`.
	static func value<T>(ofType type: T.Type, forName name: String) throws -> T {
		return try value(ofType: type, forKeys: keys(for: name))
	}
	
	/// Invoke `sysctl` with an array of identifers, interpreting the returned buffer as a `String`. This function will throw `Error.malformedUTF8` if the buffer returned from `sysctl` cannot be interpreted as a UTF8 buffer.
	static func string(for keys: [Int32]) throws -> String {
		let optionalString = try data(for: keys).withUnsafeBufferPointer() { dataPointer -> String? in
			dataPointer.baseAddress.flatMap { String(validatingUTF8: $0) }
		}
		guard let s = optionalString else {
			throw Error.malformedUTF8
		}
		return s
	}
	
	/// Invoke `sysctl` with an array of identifers, interpreting the returned buffer as a `String`. This function will throw `Error.malformedUTF8` if the buffer returned from `sysctl` cannot be interpreted as a UTF8 buffer.
	static func string(for keys: Int32...) throws -> String {
		return try string(for: keys)
	}
	
	/// Invoke `sysctl` with the specified name, interpreting the returned buffer as a `String`. This function will throw `Error.malformedUTF8` if the buffer returned from `sysctl` cannot be interpreted as a UTF8 buffer.
	static func string(for name: String) throws -> String {
		return try string(for: keys(for: name))
	}
	
	/// e.g. "MyComputer.local" (from System Preferences -> Sharing -> Computer Name) or
	/// "My-Name-iPhone" (from Settings -> General -> About -> Name)
	static var hostName: String { return try! Sysctl.string(for: [CTL_KERN, KERN_HOSTNAME]) }
	
	/// e.g. "x86_64" or "N71mAP"
	/// NOTE: this is *corrected* on iOS devices to fetch hw.model
	static var machine: String {
		#if os(iOS) && !arch(x86_64) && !arch(i386)
			return try! Sysctl.string(for: [CTL_HW, HW_MODEL])
		#else
			return try! Sysctl.string(for: [CTL_HW, HW_MACHINE])
		#endif
	}
	
	/// e.g. "MacPro4,1" or "iPhone8,1"
	/// NOTE: this is *corrected* on iOS devices to fetch hw.machine
	static var model: String {
		#if os(iOS) && !arch(x86_64) && !arch(i386)
			return try! Sysctl.string(for: [CTL_HW, HW_MACHINE])
		#else
			return try! Sysctl.string(for: [CTL_HW, HW_MODEL])
		#endif
	}
	
	/// e.g. "8" or "2"
	static var activeCPUs: Int32 { return try! Sysctl.value(ofType: Int32.self, forKeys: [CTL_HW, HW_AVAILCPU]) }
	
	/// e.g. "15.3.0" or "15.0.0"
	static var osRelease: String { return try! Sysctl.string(for: [CTL_KERN, KERN_OSRELEASE]) }
	
	/// e.g. "Darwin" or "Darwin"
	static var osType: String { return try! Sysctl.string(for: [CTL_KERN, KERN_OSTYPE]) }
	
	/// e.g. "15D21" or "13D20"
	static var osVersion: String { return try! Sysctl.string(for: [CTL_KERN, KERN_OSVERSION]) }
	
	/// e.g. "Darwin Kernel Version 15.3.0: Thu Dec 10 18:40:58 PST 2015; root:xnu-3248.30.4~1/RELEASE_X86_64" or
	/// "Darwin Kernel Version 15.0.0: Wed Dec  9 22:19:38 PST 2015; root:xnu-3248.31.3~2/RELEASE_ARM64_S8000"
	static var version: String { return try! Sysctl.string(for: [CTL_KERN, KERN_VERSION]) }
	
	#if os(macOS)
		/// e.g. 199506 (not available on iOS)
		static var osRev: Int32 { return try! Sysctl.value(ofType: Int32.self, forKeys: [CTL_KERN, KERN_OSREV]) }

		/// e.g. 2659000000 (not available on iOS)
		static var cpuFreq: Int64 { return try! Sysctl.value(ofType: Int64.self, forName: "hw.cpufrequency") }

		/// e.g. 25769803776 (not available on iOS)
		static var memSize: UInt64 { return try! Sysctl.value(ofType: UInt64.self, forKeys: [CTL_HW, HW_MEMSIZE]) }
	#endif
}

import Foundation

/// A class wrapper around a type (usually a value type) so it can be moved without copying.
class Box<T> {
	fileprivate(set) var value: T
	init(_ t: T) {
		value = t
	}
}

//// A class wrapper around a type (usually a value type) so changes to it can be shared (usually as an ad hoc communication channel). NOTE: this version is *not* threadsafe, use AtomicBox for that.
final class MutableBox<T>: Box<T> {
	override var value: T { get { return super.value } set { super.value = newValue } }
	override init(_ t: T) {
		super.init(t)
	}
}

// A class wrapper around a type (usually a value type) so changes to it can be shared in a thread-safe manner (usually as an ad hoc communication channel).
/// "Atomic" in this sense refers to the semantics, not the implementation. This uses a pthread mutex, not CAS-style atomic operations.
final class AtomicBox<T> {
	private var mutex = PThreadMutex()
	private var internalValue: T
	
	init(_ t: T) {
		internalValue = t
	}
	
	var value: T {
		get {
			mutex.unbalancedLock()
			defer { mutex.unbalancedUnlock() }
			return internalValue
		}
	}

	@discardableResult
	func mutate(_ f: (inout T) throws -> Void) rethrows -> T {
		mutex.unbalancedLock()
		defer { mutex.unbalancedUnlock() }
		try f(&internalValue)
		return internalValue
	}
}

/// A struct wrapper around an optional and a construction function that presents the optional through the `value()` function as though it's a lazy var. Unlike a true lazy var, you can query if the value has been initialized.
struct Lazy<T> {
	var valueIfInitialized: T?
	let valueConstructor: () -> T
	
	init(valueConstructor: @escaping () -> T) {
		self.valueConstructor = valueConstructor
	}
	var isInitialized: Bool { return valueIfInitialized != nil }
	mutating func value() -> T {
		if let v = valueIfInitialized {
			return v
		}
		let v = valueConstructor()
		valueIfInitialized = v
		return v
	}
}

/// A wrapper around a type (usually a class type) so it can be weakly referenced from an Array or other strong container.
struct Weak<T: AnyObject> {
	weak var value: T?
	
	init(_ value: T?) {
		self.value = value
	}
	
	func contains(_ other: T) -> Bool {
		if let v = value {
			return v === other
		} else {
			return false
		}
	}
}

/// A wrapper around a type (usually a class type) so it can be referenced unowned from an Array or other strong container.
struct Unowned<T: AnyObject> {
	unowned let value: T
	init(_ value: T) {
		self.value = value
	}
}

/// A enum wrapper around a type (usually a class type) so its ownership can be set at runtime.
enum PossiblyWeak<T: AnyObject> {
	case strong(T)
	case weak(Weak<T>)
	
	init(strong value: T) {
		self = PossiblyWeak<T>.strong(value)
	}
	
	init(weak value: T) {
		self = PossiblyWeak<T>.weak(Weak(value))
	}
	
	var value: T? {
		switch self {
		case .strong(let t): return t
		case .weak(let weakT): return weakT.value
		}
	}
	
	func contains(_ other: T) -> Bool {
		switch self {
		case .strong(let t): return t === other
		case .weak(let weakT):
			if let wt = weakT.value {
				return wt === other
			}
			return false
		}
	}
}
